{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "DL-Assignment-2-pyTorch.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "7297a27664f840f0a9c15b9d6e56379d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_f7e38c29c5704f37bc028b8c05e0d435",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_ca6d652d6f27404ca411eea89649c358",
              "IPY_MODEL_e5ab5ce429854932890da1f51affaa25",
              "IPY_MODEL_c430963212284a3cb194a1cf82db5178"
            ]
          }
        },
        "f7e38c29c5704f37bc028b8c05e0d435": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "ca6d652d6f27404ca411eea89649c358": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_bce2c1a6c267439bb12987515958be58",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "100%",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_3d0a98124b0d4fd3813a64742b498b42"
          }
        },
        "e5ab5ce429854932890da1f51affaa25": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_f2db9718c27946ca9e3aa9b3cceb22ca",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 100,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 100,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_ac014a85bfd14070a6588b76bafc0faa"
          }
        },
        "c430963212284a3cb194a1cf82db5178": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_f1fa2da315f94d3889d5e9d20511c46a",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 100/100 [00:06&lt;00:00, 16.92it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_79b1e9f8d2274e5aba7152b036b41eff"
          }
        },
        "bce2c1a6c267439bb12987515958be58": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "3d0a98124b0d4fd3813a64742b498b42": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "f2db9718c27946ca9e3aa9b3cceb22ca": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "ac014a85bfd14070a6588b76bafc0faa": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "f1fa2da315f94d3889d5e9d20511c46a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "79b1e9f8d2274e5aba7152b036b41eff": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "C8nY3U5NlXlS"
      },
      "outputs": [],
      "source": [
        "## Standard libraries\n",
        "import os\n",
        "import math\n",
        "import numpy as np \n",
        "import time\n",
        "\n",
        "## Imports for plotting\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline \n",
        "from IPython.display import set_matplotlib_formats\n",
        "set_matplotlib_formats('svg', 'pdf') # For export\n",
        "from matplotlib.colors import to_rgba\n",
        "import seaborn as sns\n",
        "sns.set()\n",
        "\n",
        "## Progress bar\n",
        "from tqdm.notebook import tqdm"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **PyTorch Basics**\n",
        "\n",
        "Importing PyTorch"
      ],
      "metadata": {
        "id": "8gKAzmmXla9Q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "print(\"Using torch\", torch.__version__)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "05VwaD2Hl6Hu",
        "outputId": "355a7bb5-6609-4cba-9263-437d68c5b8cd"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using torch 1.10.0+cu111\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "PyTorch provides functions that are stochastic like generating random numbers. However, a very good practice is to setup your code to be reproducible with the exact same random numbers. This is why we set a seed below."
      ],
      "metadata": {
        "id": "MY6PfHPtmL5R"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "torch.manual_seed(42) # Setting the seed"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L9Xgfp5jmNOe",
        "outputId": "f3610f52-34c7-4961-ddd4-778d0a93eec1"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<torch._C.Generator at 0x7f923d853df0>"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Initialization**\n",
        "\n",
        "\n",
        "Let's first start by looking at different ways of creating a tensor. There are many possible options, the most simple one is to call torch.Tensor passing the desired shape as input argument:"
      ],
      "metadata": {
        "id": "H-MSvflumRR6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x = torch.Tensor(2, 3, 4)\n",
        "print(x)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KQYwhdLHm7KZ",
        "outputId": "e3d9ea9f-1b3a-4979-c403-d7b4078ae172"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[[1.1565e-35, 3.0658e-41, 7.0065e-44, 7.0065e-44],\n",
            "         [6.3058e-44, 6.7262e-44, 7.0065e-44, 6.3058e-44],\n",
            "         [7.0065e-44, 7.2868e-44, 1.1771e-43, 6.7262e-44]],\n",
            "\n",
            "        [[7.1466e-44, 8.1275e-44, 7.0065e-44, 7.5670e-44],\n",
            "         [8.1275e-44, 7.0065e-44, 7.9874e-44, 6.4460e-44],\n",
            "         [6.8664e-44, 7.8473e-44, 7.8473e-44, 7.0065e-44]]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The function torch.Tensor allocates memory for the desired tensor, but reuses any values that have already been in the memory. To directly assign values to the tensor during initialization, there are many alternatives including:\n",
        "\n",
        "**torch.zeros:** Creates a tensor filled with zeros\n",
        "\n",
        "**torch.ones:** Creates a tensor filled with ones\n",
        "\n",
        "**torch.rand:** Creates a tensor with random values uniformly sampled between 0 and 1\n",
        "\n",
        "**torch.randn:** Creates a tensor with random values sampled from a normal distribution with mean 0 and variance 1\n",
        "\n",
        "**torch.arange:** Creates a tensor containing the values N,N+1,N+2,...,M\n",
        "\n",
        "**torch.Tensor (input list):** Creates a tensor from the list elements you provide"
      ],
      "metadata": {
        "id": "Moz1T7y9nAJW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a tensor from a (nested) list\n",
        "x = torch.Tensor([[1, 2], [3, 4]])\n",
        "print(x)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bLVRLdmmnZfj",
        "outputId": "a6a41fde-c1b6-44ab-83ba-f4e375c3a001"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[1., 2.],\n",
            "        [3., 4.]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a tensor with random values between 0 and 1 with the shape [2, 3, 4]\n",
        "x = torch.rand(2, 3, 4)\n",
        "print(x)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4dwBWYVLnnlK",
        "outputId": "043b34d4-abdd-453a-f308-e8a11afc7d82"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[[0.8823, 0.9150, 0.3829, 0.9593],\n",
            "         [0.3904, 0.6009, 0.2566, 0.7936],\n",
            "         [0.9408, 0.1332, 0.9346, 0.5936]],\n",
            "\n",
            "        [[0.8694, 0.5677, 0.7411, 0.4294],\n",
            "         [0.8854, 0.5739, 0.2666, 0.6274],\n",
            "         [0.2696, 0.4414, 0.2969, 0.8317]]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "shape = x.shape\n",
        "print(\"Shape:\", x.shape)\n",
        "\n",
        "size = x.size()\n",
        "print(\"Size:\", size)\n",
        "\n",
        "dim1, dim2, dim3 = x.size()\n",
        "print(\"Size:\", dim1, dim2, dim3)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N18Tm9ZknoYx",
        "outputId": "17384448-5d3a-485f-92bf-1cc583681bc1"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape: torch.Size([2, 3, 4])\n",
            "Size: torch.Size([2, 3, 4])\n",
            "Size: 2 3 4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Tensor to Numpy and vice versa**"
      ],
      "metadata": {
        "id": "8OH8SXlinvDV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Tensors can be converted to numpy arrays, and numpy arrays back to tensors. To transform a numpy array into a tensor, we can use the function **torch.from_numpy**:"
      ],
      "metadata": {
        "id": "ztMeOhuGn3OX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "np_arr = np.array([[1, 2], [3, 4]])\n",
        "tensor = torch.from_numpy(np_arr)\n",
        "\n",
        "print(\"Numpy array:\", np_arr)\n",
        "print(\"PyTorch tensor:\", tensor)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zEFK0niBntGM",
        "outputId": "6ac1aab5-f7fb-46e8-9b4a-bfbcffee9062"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Numpy array: [[1 2]\n",
            " [3 4]]\n",
            "PyTorch tensor: tensor([[1, 2],\n",
            "        [3, 4]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "To transform a PyTorch tensor back to a numpy array, we can use the function .numpy() on tensors\n",
        "\n",
        "Note : The conversion of tensors to numpy require the tensor to be on the CPU, and not the GPU"
      ],
      "metadata": {
        "id": "w251GW9Ln8Qo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tensor = torch.arange(4)\n",
        "np_arr = tensor.numpy()\n",
        "\n",
        "print(\"PyTorch tensor:\", tensor)\n",
        "print(\"Numpy array:\", np_arr)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fyPCrY_coCfx",
        "outputId": "0c9475e7-578b-464b-efab-633b1c8b5374"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "PyTorch tensor: tensor([0, 1, 2, 3])\n",
            "Numpy array: [0 1 2 3]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4Cv_d8d_lF67"
      },
      "source": [
        "**Operations**\n",
        "\n",
        "Most operations that exist in numpy, also exist in PyTorch.\n",
        "\n",
        "The simplest operation is to add two tensors:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "AuwnjfJ_lF67",
        "outputId": "91ed845b-1eea-45c5-b4dc-a177f6b37606",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "X1 tensor([[0.1053, 0.2695, 0.3588],\n",
            "        [0.1994, 0.5472, 0.0062]])\n",
            "X2 tensor([[0.9516, 0.0753, 0.8860],\n",
            "        [0.5832, 0.3376, 0.8090]])\n",
            "Y tensor([[1.0569, 0.3448, 1.2448],\n",
            "        [0.7826, 0.8848, 0.8151]])\n"
          ]
        }
      ],
      "source": [
        "x1 = torch.rand(2, 3)\n",
        "x2 = torch.rand(2, 3)\n",
        "y = x1 + x2\n",
        "\n",
        "print(\"X1\", x1)\n",
        "print(\"X2\", x2)\n",
        "print(\"Y\", y)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zm79Fit9lF68"
      },
      "source": [
        "Calling `x1 + x2` creates a new tensor containing the sum of the two inputs. However, we can also use in-place operations that are applied directly on the memory of a tensor. We therefore change the values of `x2` without the chance to re-accessing the values of `x2` before the operation. An example is shown below:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "qXVltMfslF68",
        "outputId": "6ba6a005-09fb-4002-e89e-00f3f45a7fa4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "X1 (before) tensor([[0.5779, 0.9040, 0.5547],\n",
            "        [0.3423, 0.6343, 0.3644]])\n",
            "X2 (before) tensor([[0.7104, 0.9464, 0.7890],\n",
            "        [0.2814, 0.7886, 0.5895]])\n",
            "X1 (after) tensor([[0.5779, 0.9040, 0.5547],\n",
            "        [0.3423, 0.6343, 0.3644]])\n",
            "X2 (after) tensor([[1.2884, 1.8504, 1.3437],\n",
            "        [0.6237, 1.4230, 0.9539]])\n"
          ]
        }
      ],
      "source": [
        "x1 = torch.rand(2, 3)\n",
        "x2 = torch.rand(2, 3)\n",
        "print(\"X1 (before)\", x1)\n",
        "print(\"X2 (before)\", x2)\n",
        "\n",
        "x2.add_(x1)\n",
        "print(\"X1 (after)\", x1)\n",
        "print(\"X2 (after)\", x2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pToiKpq_lF68"
      },
      "source": [
        "In-place operations are usually marked with a underscore postfix (e.g. \"add_\" instead of \"add\").\n",
        "\n",
        "Another common operation aims at changing the shape of a tensor. A tensor of size (2,3) can be re-organized to any other shape with the same number of elements (e.g. a tensor of size (6), or (3,2), ...). In PyTorch, this operation is called `view`:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "MoQtDKHDlF69",
        "outputId": "276c2ce5-e4ed-46e4-ac09-e8e0b7f5452c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "X tensor([0, 1, 2, 3, 4, 5])\n"
          ]
        }
      ],
      "source": [
        "x = torch.arange(6)\n",
        "print(\"X\", x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "8yJobLs6lF69",
        "outputId": "f24f6a79-6a48-48e3-bdd8-eb3b94204d91",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "X tensor([[0, 1, 2],\n",
            "        [3, 4, 5]])\n"
          ]
        }
      ],
      "source": [
        "x = x.view(2, 3)\n",
        "print(\"X\", x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "5P8I2xj2lF69",
        "outputId": "c7059169-c176-4cea-bfd3-08d88e81bf3e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "X tensor([[0, 3],\n",
            "        [1, 4],\n",
            "        [2, 5]])\n"
          ]
        }
      ],
      "source": [
        "x = x.permute(1, 0) # Swapping dimension 0 and 1\n",
        "print(\"X\", x)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MvL4WAYnlF69"
      },
      "source": [
        "Other commonly used operations include matrix multiplications, which are essential for neural networks. Quite often, we have an input vector $\\mathbf{x}$, which is transformed using a learned weight matrix $\\mathbf{W}$. There are multiple ways and functions to perform matrix multiplication, some of which we list below:\n",
        "\n",
        "* `torch.matmul`: Performs the matrix product over two tensors, where the specific behavior depends on the dimensions. If both inputs are matrices (2-dimensional tensors), it performs the standard matrix product. For higher dimensional inputs, the function supports broadcasting . Can also be written as `a @ b`, similar to numpy. \n",
        "* `torch.mm`: Performs the matrix product over two matrices, but doesn't support broadcasting.\n",
        "* `torch.bmm`: Performs the matrix product with a support batch dimension. If the first tensor $T$ is of shape ($b\\times n\\times m$), and the second tensor $R$ ($b\\times m\\times p$), the output $O$ is of shape ($b\\times n\\times p$), and has been calculated by performing $b$ matrix multiplications of the submatrices of $T$ and $R$: $O_i = T_i @ R_i$\n",
        "* `torch.einsum`: Performs matrix multiplications and more (i.e. sums of products) using the Einstein summation convention. Explanation of the Einstein sum can be found in assignment 1.\n",
        "\n",
        "Usually, we use `torch.matmul` or `torch.bmm`. We can try a matrix multiplication with `torch.matmul` below."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "-_84U9U8lF69",
        "outputId": "5c3a3e2d-6694-4be7-895a-84d4eace196a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "X tensor([[0, 1, 2],\n",
            "        [3, 4, 5]])\n"
          ]
        }
      ],
      "source": [
        "x = torch.arange(6)\n",
        "x = x.view(2, 3)\n",
        "print(\"X\", x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "YAg3gBE6lF6-",
        "outputId": "b48bdc48-4548-4add-9b46-15074f024a26",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "W tensor([[0, 1, 2],\n",
            "        [3, 4, 5],\n",
            "        [6, 7, 8]])\n"
          ]
        }
      ],
      "source": [
        "W = torch.arange(9).view(3, 3) # We can also stack multiple operations in a single line\n",
        "print(\"W\", W)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "izerLQY5lF6-",
        "outputId": "4e2a5fa3-b59a-400d-ac20-fd20b90f1bd1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "h tensor([[15, 18, 21],\n",
            "        [42, 54, 66]])\n"
          ]
        }
      ],
      "source": [
        "h = torch.matmul(x, W) # Verify the result by calculating it by hand too!\n",
        "print(\"h\", h)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x_llQlXylF6-"
      },
      "source": [
        "**Indexing**\n",
        "\n",
        "We often have the situation where we need to select a part of a tensor."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "ChWQjO8jlF6_",
        "outputId": "599b36fb-c0b8-4858-ffc8-bc1f5511f67d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "X tensor([[ 0,  1,  2,  3],\n",
            "        [ 4,  5,  6,  7],\n",
            "        [ 8,  9, 10, 11]])\n"
          ]
        }
      ],
      "source": [
        "x = torch.arange(12).view(3, 4)\n",
        "print(\"X\", x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "7l5nGJALlF6_",
        "outputId": "f0f37830-b502-49e1-c3b6-6eca6ae37f43",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([1, 5, 9])\n"
          ]
        }
      ],
      "source": [
        "print(x[:, 1])   # Second column"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "E5YH7WonlF6_",
        "outputId": "eefed19a-4e65-4621-d79d-5368745b7d25",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([0, 1, 2, 3])\n"
          ]
        }
      ],
      "source": [
        "print(x[0])      # First row"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "UhYfvMthlF6_",
        "outputId": "e77d95b9-0ed8-4161-d7e6-f3c88fbc3c2b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([3, 7])\n"
          ]
        }
      ],
      "source": [
        "print(x[:2, -1]) # First two rows, last column"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "UPP2IglQlF7A",
        "outputId": "ba424879-80b5-4610-d31f-693165d6122d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[ 4,  5,  6,  7],\n",
            "        [ 8,  9, 10, 11]])\n"
          ]
        }
      ],
      "source": [
        "print(x[1:3, :]) # Middle two rows"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Dynamic computation graph and back propagation**\n",
        "\n",
        "\n",
        "PyTorch is a define-by-run framework; this means that we can just do our manipulations, and PyTorch will keep track of that graph for us. Thus, we create a dynamic computation graph along the way."
      ],
      "metadata": {
        "id": "RIxkMAQMqXvj"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "arowb5CRlF7B",
        "outputId": "bfd9ffab-4c28-41e5-8e01-41968cbf24eb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "False\n"
          ]
        }
      ],
      "source": [
        "x = torch.ones((3,))\n",
        "print(x.requires_grad)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ubo0m_RalF7C"
      },
      "source": [
        "We can change this for an existing tensor using the function `requires_grad_()` (underscore indicating that this is a in-place operation). Alternatively, when creating a tensor, you can pass the argument `requires_grad=True` to most initializers we have seen above."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "5maw2IC_lF7D",
        "outputId": "ceda8420-ccc0-4f29-f6ae-e0a2371adea9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "True\n"
          ]
        }
      ],
      "source": [
        "x.requires_grad_(True)\n",
        "print(x.requires_grad)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WXRb14gylF7D"
      },
      "source": [
        "In order to get familiar with the concept of a computation graph, we will create one for the following function:\n",
        "\n",
        "$$y = \\frac{1}{|x|}\\sum_i \\left[(x_i + 2)^2 + 3\\right]$$\n",
        "\n",
        "You could imagine that $x$ are our parameters, and we want to optimize (either maximize or minimize) the output $y$. For this, we want to obtain the gradients $\\partial y / \\partial \\mathbf{x}$. For our example, we'll use $\\mathbf{x}=[0,1,2]$ as our input."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "SMdrw710lF7D",
        "outputId": "45c9d40b-b578-4d57-f14d-aacc06d1c9f3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "X tensor([0., 1., 2.], requires_grad=True)\n"
          ]
        }
      ],
      "source": [
        "x = torch.arange(3, dtype=torch.float32, requires_grad=True) # Only float tensors can have gradients\n",
        "print(\"X\", x)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aZaL6lxZlF7E"
      },
      "source": [
        "Now let's build the computation graph step by step. You can combine multiple operations in a single line, but we will separate them here to get a better understanding of how each operation is added to the computation graph."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "n9BMHBF2lF7E",
        "outputId": "5a148595-b2d2-4213-b549-cb5bded810b4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Y tensor(12.6667, grad_fn=<MeanBackward0>)\n"
          ]
        }
      ],
      "source": [
        "a = x + 2\n",
        "b = a ** 2\n",
        "c = b + 3\n",
        "y = c.mean()\n",
        "print(\"Y\", y)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "qBGt46cWlF7F"
      },
      "outputs": [],
      "source": [
        "y.backward()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VNmsP_zClF7F"
      },
      "source": [
        "`x.grad` will now contain the gradient $\\partial y/ \\partial \\mathcal{x}$, and this gradient indicates how a change in $\\mathbf{x}$ will affect output $y$ given the current input $\\mathbf{x}=[0,1,2]$:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "zYFZVEcjlF7F",
        "outputId": "4b5ce44d-bd0a-4d00-e5be-7987fbc1869e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([1.3333, 2.0000, 2.6667])\n"
          ]
        }
      ],
      "source": [
        "print(x.grad)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Uh6K1WeOlF7G"
      },
      "source": [
        "We can also verify these gradients by hand. We will calculate the gradients using the chain rule, in the same way as PyTorch did it:\n",
        "\n",
        "$$\\frac{\\partial y}{\\partial x_i} = \\frac{\\partial y}{\\partial c_i}\\frac{\\partial c_i}{\\partial b_i}\\frac{\\partial b_i}{\\partial a_i}\\frac{\\partial a_i}{\\partial x_i}$$\n",
        "\n",
        "Note that we have simplified this equation to index notation, and by using the fact that all operation besides the mean do not combine the elements in the tensor. The partial derivatives are:\n",
        "\n",
        "$$\n",
        "\\frac{\\partial a_i}{\\partial x_i} = 1,\\hspace{1cm}\n",
        "\\frac{\\partial b_i}{\\partial a_i} = 2\\cdot a_i\\hspace{1cm}\n",
        "\\frac{\\partial c_i}{\\partial b_i} = 1\\hspace{1cm}\n",
        "\\frac{\\partial y}{\\partial c_i} = \\frac{1}{3}\n",
        "$$\n",
        "\n",
        "Hence, with the input being $\\mathbf{x}=[0,1,2]$, our gradients are $\\partial y/\\partial \\mathbf{x}=[4/3,2,8/3]$. The previous code cell should have printed the same result."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Model Building using pyTorch**"
      ],
      "metadata": {
        "id": "_5H3dFSirUGv"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ggHTTaN1lF7J"
      },
      "source": [
        "The package `torch.nn` defines a series of useful classes like linear networks layers, activation functions, loss functions etc."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "Lf6eECKKlF7J"
      },
      "outputs": [],
      "source": [
        "import torch.nn as nn"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rSqhPSPKlF7K"
      },
      "source": [
        "Additionally to `torch.nn`, there is also `torch.nn.functional`. It contains functions that are used in network layers. This is in contrast to `torch.nn` which defines them as `nn.Modules` (more on it below), and `torch.nn` actually uses a lot of functionalities from `torch.nn.functional`. Hence, the functional package is useful in many situations, and so we import it as well here."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "1UTi7mLwlF7K"
      },
      "outputs": [],
      "source": [
        "import torch.nn.functional as F"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HNUKOFJElF7K"
      },
      "source": [
        "**nn.Module**\n",
        "\n",
        "In PyTorch, a neural network is built up out of modules. Modules can contain other modules, and a neural network is considered to be a module itself as well. The basic template of a module is as follows:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "V-VEPNgAlF7K"
      },
      "outputs": [],
      "source": [
        "class MyModule(nn.Module):\n",
        "    \n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        # Some init for my module\n",
        "        \n",
        "    def forward(self, x):\n",
        "        # Function for performing the calculation of the module.\n",
        "        pass"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_C2YKWbBlF7K"
      },
      "source": [
        "The forward function is where the computation of the module is taken place, and is executed when you call the module (`nn = MyModule(); nn(x)`). In the init function, we usually create the parameters of the module, using `nn.Parameter`, or defining other modules that are used in the forward function. The backward calculation is done automatically, but could be overwritten as well if wanted.\n",
        "\n",
        "**Simple classifier**\n",
        "\n",
        "\n",
        "We can now make use of the pre-defined modules in the `torch.nn` package, and define our own small neural network. We will use a minimal network with a input layer, one hidden layer with tanh as activation function, and a output layer. In other words, our networks should look something like this:\n",
        "\n",
        "The input neurons are shown in blue, which represent the coordinates $x_1$ and $x_2$ of a data point. The hidden neurons including a tanh activation are shown in white, and the output neuron in red.\n",
        "In PyTorch, we can define this as follows:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "OPciUob6lF7K"
      },
      "outputs": [],
      "source": [
        "class SimpleClassifier(nn.Module):\n",
        "\n",
        "    def __init__(self, num_inputs, num_hidden, num_outputs):\n",
        "        super().__init__()\n",
        "        # Initialize the modules we need to build the network\n",
        "        self.linear1 = nn.Linear(num_inputs, num_hidden)\n",
        "        self.act_fn = nn.Tanh()\n",
        "        self.linear2 = nn.Linear(num_hidden, num_outputs)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # Perform the calculation of the model to determine the prediction\n",
        "        x = self.linear1(x)\n",
        "        x = self.act_fn(x)\n",
        "        x = self.linear2(x)\n",
        "        return x"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5Nci5LgFlF7K"
      },
      "source": [
        "For the examples in this notebook, we will use a tiny neural network with two input neurons and four hidden neurons. As we perform binary classification, we will use a single output neuron. Note that we do not apply a sigmoid on the output yet. This is because other functions, especially the loss, are more efficient and precise to calculate on the original outputs instead of the sigmoid output. We will discuss the detailed reason later."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "W52DVpjZlF7K",
        "outputId": "0e977747-ebf4-489a-a6b8-dcd79ee2b04a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "SimpleClassifier(\n",
            "  (linear1): Linear(in_features=2, out_features=4, bias=True)\n",
            "  (act_fn): Tanh()\n",
            "  (linear2): Linear(in_features=4, out_features=1, bias=True)\n",
            ")\n"
          ]
        }
      ],
      "source": [
        "model = SimpleClassifier(num_inputs=2, num_hidden=4, num_outputs=1)\n",
        "# Printing a module shows all its submodules\n",
        "print(model)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uXKp9bj5lF7L"
      },
      "source": [
        "Printing the model lists all submodules it contains. The parameters of a module can be obtained by using its `parameters()` functions, or `named_parameters()` to get a name to each parameter object. For our small neural network, we have the following parameters:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "F-Kr8iwAlF7L",
        "outputId": "4e2ef647-5e43-47d4-d784-7594906799c8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Parameter linear1.weight, shape torch.Size([4, 2])\n",
            "Parameter linear1.bias, shape torch.Size([4])\n",
            "Parameter linear2.weight, shape torch.Size([1, 4])\n",
            "Parameter linear2.bias, shape torch.Size([1])\n"
          ]
        }
      ],
      "source": [
        "for name, param in model.named_parameters():\n",
        "    print(f\"Parameter {name}, shape {param.shape}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bcjydvt2lF7L"
      },
      "source": [
        "Each linear layer has a weight matrix of the shape `[output, input]`, and a bias of the shape `[output]`. The tanh activation function does not have any parameters. Note that parameters are only registered for `nn.Module` objects that are direct object attributes, i.e. `self.a = ...`."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "svBg6l2utyTI"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kW4xr8bFlF7L"
      },
      "source": [
        "**The data**\n",
        "\n",
        "PyTorch also provides a few functionalities to load the training and test data efficiently, summarized in the package `torch.utils.data`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "id": "03W1aZxvlF7L"
      },
      "outputs": [],
      "source": [
        "import torch.utils.data as data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LonD8MZClF7L"
      },
      "source": [
        "The data package defines two classes which are the standard interface for handling data in PyTorch: `data.Dataset`, and `data.DataLoader`. The dataset class provides an uniform interface to access the training/test data, while the data loader makes sure to efficiently load and stack the data points from the dataset into batches during training."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8Xd1YY19lF7L"
      },
      "source": [
        "**The dataset class**\n",
        "\n",
        "The dataset class summarizes the basic functionality of a dataset in a natural way. To define a dataset in PyTorch, we simply specify two functions: `__getitem__`, and `__len__`. The get-item function has to return the $i$-th data point in the dataset, while the len function returns the size of the dataset. For the XOR dataset, we can define the dataset class as follows:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "id": "GnRwQrpwlF7M"
      },
      "outputs": [],
      "source": [
        "class XORDataset(data.Dataset):\n",
        "\n",
        "    def __init__(self, size, std=0.1):\n",
        "        \"\"\"\n",
        "        Inputs:\n",
        "            size - Number of data points we want to generate\n",
        "            std - Standard deviation of the noise (see generate_continuous_xor function)\n",
        "        \"\"\"\n",
        "        super().__init__()\n",
        "        self.size = size\n",
        "        self.std = std\n",
        "        self.generate_continuous_xor()\n",
        "\n",
        "    def generate_continuous_xor(self):\n",
        "        # Each data point in the XOR dataset has two variables, x and y, that can be either 0 or 1\n",
        "        # The label is their XOR combination, i.e. 1 if only x or only y is 1 while the other is 0.\n",
        "        # If x=y, the label is 0.\n",
        "        data = torch.randint(low=0, high=2, size=(self.size, 2), dtype=torch.float32)\n",
        "        label = (data.sum(dim=1) == 1).to(torch.long)\n",
        "        # To make it slightly more challenging, we add a bit of gaussian noise to the data points.\n",
        "        data += self.std * torch.randn(data.shape)\n",
        "\n",
        "        self.data = data\n",
        "        self.label = label\n",
        "\n",
        "    def __len__(self):\n",
        "        # Number of data point we have. Alternatively self.data.shape[0], or self.label.shape[0]\n",
        "        return self.size\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        # Return the idx-th data point of the dataset\n",
        "        # If we have multiple things to return (data point and label), we can return them as tuple\n",
        "        data_point = self.data[idx]\n",
        "        data_label = self.label[idx]\n",
        "        return data_point, data_label"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z1QcC_YxlF7M"
      },
      "source": [
        "Let's try to create such a dataset and inspect it:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "id": "Ii6Gjkq_lF7M",
        "outputId": "c717ce82-9ac3-4a97-985e-1b5cfc0f50a3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Size of dataset: 200\n",
            "Data point 0: (tensor([0.9316, 1.0066]), tensor(0))\n"
          ]
        }
      ],
      "source": [
        "dataset = XORDataset(size=200)\n",
        "print(\"Size of dataset:\", len(dataset))\n",
        "print(\"Data point 0:\", dataset[0])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lDWQ5_zVlF7M"
      },
      "source": [
        "To better relate to the dataset, we visualize the samples below. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "id": "QFjQB-UNlF7M"
      },
      "outputs": [],
      "source": [
        "def visualize_samples(data, label):\n",
        "    if isinstance(data, torch.Tensor):\n",
        "        data = data.cpu().numpy()\n",
        "    if isinstance(label, torch.Tensor):\n",
        "        label = label.cpu().numpy()\n",
        "    data_0 = data[label == 0]\n",
        "    data_1 = data[label == 1]\n",
        "    \n",
        "    plt.figure(figsize=(4,4))\n",
        "    plt.scatter(data_0[:,0], data_0[:,1], edgecolor=\"#333\", label=\"Class 0\")\n",
        "    plt.scatter(data_1[:,0], data_1[:,1], edgecolor=\"#333\", label=\"Class 1\")\n",
        "    plt.title(\"Dataset samples\")\n",
        "    plt.ylabel(r\"$x_2$\")\n",
        "    plt.xlabel(r\"$x_1$\")\n",
        "    plt.legend()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "id": "H5KdAUmNlF7M",
        "outputId": "30d2253a-01f4-4729-cf1e-c398d4603b5c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 398
        }
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/pdf": "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\n",
            "text/plain": [
              "<Figure size 288x288 with 1 Axes>"
            ],
            "image/svg+xml": "<?xml version=\"1.0\" encoding=\"utf-8\" standalone=\"no\"?>\n<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n  \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n<!-- Created with matplotlib (https://matplotlib.org/) -->\n<svg height=\"282.717813pt\" version=\"1.1\" viewBox=\"0 0 289.424844 282.717813\" width=\"289.424844pt\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n <defs>\n  <style type=\"text/css\">\n*{stroke-linecap:butt;stroke-linejoin:round;}\n  </style>\n </defs>\n <g id=\"figure_1\">\n  <g id=\"patch_1\">\n   <path d=\"M 0 282.717813 \nL 289.424844 282.717813 \nL 289.424844 0 \nL 0 0 \nz\n\" style=\"fill:none;\"/>\n  </g>\n  <g id=\"axes_1\">\n   <g id=\"patch_2\">\n    <path d=\"M 59.024844 239.758125 \nL 282.224844 239.758125 \nL 282.224844 22.318125 \nL 59.024844 22.318125 \nz\n\" style=\"fill:#eaeaf2;\"/>\n   </g>\n   <g id=\"matplotlib.axis_1\">\n    <g id=\"xtick_1\">\n     <g id=\"line2d_1\">\n      <path clip-path=\"url(#p923ca5c768)\" d=\"M 110.44057 239.758125 \nL 110.44057 22.318125 \n\" style=\"fill:none;stroke:#ffffff;stroke-linecap:round;\"/>\n     </g>\n     <g id=\"text_1\">\n      <!-- 0.0 -->\n      <defs>\n       <path d=\"M 31.78125 66.40625 \nQ 24.171875 66.40625 20.328125 58.90625 \nQ 16.5 51.421875 16.5 36.375 \nQ 16.5 21.390625 20.328125 13.890625 \nQ 24.171875 6.390625 31.78125 6.390625 \nQ 39.453125 6.390625 43.28125 13.890625 \nQ 47.125 21.390625 47.125 36.375 \nQ 47.125 51.421875 43.28125 58.90625 \nQ 39.453125 66.40625 31.78125 66.40625 \nz\nM 31.78125 74.21875 \nQ 44.046875 74.21875 50.515625 64.515625 \nQ 56.984375 54.828125 56.984375 36.375 \nQ 56.984375 17.96875 50.515625 8.265625 \nQ 44.046875 -1.421875 31.78125 -1.421875 \nQ 19.53125 -1.421875 13.0625 8.265625 \nQ 6.59375 17.96875 6.59375 36.375 \nQ 6.59375 54.828125 13.0625 64.515625 \nQ 19.53125 74.21875 31.78125 74.21875 \nz\n\" id=\"DejaVuSans-48\"/>\n       <path d=\"M 10.6875 12.40625 \nL 21 12.40625 \nL 21 0 \nL 10.6875 0 \nz\n\" id=\"DejaVuSans-46\"/>\n      </defs>\n      <g style=\"fill:#262626;\" transform=\"translate(101.693851 257.616406)scale(0.11 -0.11)\">\n       <use xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\n       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_2\">\n     <g id=\"line2d_2\">\n      <path clip-path=\"url(#p923ca5c768)\" d=\"M 176.971055 239.758125 \nL 176.971055 22.318125 \n\" style=\"fill:none;stroke:#ffffff;stroke-linecap:round;\"/>\n     </g>\n     <g id=\"text_2\">\n      <!-- 0.5 -->\n      <defs>\n       <path d=\"M 10.796875 72.90625 \nL 49.515625 72.90625 \nL 49.515625 64.59375 \nL 19.828125 64.59375 \nL 19.828125 46.734375 \nQ 21.96875 47.46875 24.109375 47.828125 \nQ 26.265625 48.1875 28.421875 48.1875 \nQ 40.625 48.1875 47.75 41.5 \nQ 54.890625 34.8125 54.890625 23.390625 \nQ 54.890625 11.625 47.5625 5.09375 \nQ 40.234375 -1.421875 26.90625 -1.421875 \nQ 22.3125 -1.421875 17.546875 -0.640625 \nQ 12.796875 0.140625 7.71875 1.703125 \nL 7.71875 11.625 \nQ 12.109375 9.234375 16.796875 8.0625 \nQ 21.484375 6.890625 26.703125 6.890625 \nQ 35.15625 6.890625 40.078125 11.328125 \nQ 45.015625 15.765625 45.015625 23.390625 \nQ 45.015625 31 40.078125 35.4375 \nQ 35.15625 39.890625 26.703125 39.890625 \nQ 22.75 39.890625 18.8125 39.015625 \nQ 14.890625 38.140625 10.796875 36.28125 \nz\n\" id=\"DejaVuSans-53\"/>\n      </defs>\n      <g style=\"fill:#262626;\" transform=\"translate(168.224337 257.616406)scale(0.11 -0.11)\">\n       <use xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\n       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-53\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_3\">\n     <g id=\"line2d_3\">\n      <path clip-path=\"url(#p923ca5c768)\" d=\"M 243.501541 239.758125 \nL 243.501541 22.318125 \n\" style=\"fill:none;stroke:#ffffff;stroke-linecap:round;\"/>\n     </g>\n     <g id=\"text_3\">\n      <!-- 1.0 -->\n      <defs>\n       <path d=\"M 12.40625 8.296875 \nL 28.515625 8.296875 \nL 28.515625 63.921875 \nL 10.984375 60.40625 \nL 10.984375 69.390625 \nL 28.421875 72.90625 \nL 38.28125 72.90625 \nL 38.28125 8.296875 \nL 54.390625 8.296875 \nL 54.390625 0 \nL 12.40625 0 \nz\n\" id=\"DejaVuSans-49\"/>\n      </defs>\n      <g style=\"fill:#262626;\" transform=\"translate(234.754822 257.616406)scale(0.11 -0.11)\">\n       <use xlink:href=\"#DejaVuSans-49\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\n       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"text_4\">\n     <!-- $x_1$ -->\n     <defs>\n      <path d=\"M 60.015625 54.6875 \nL 34.90625 27.875 \nL 50.296875 0 \nL 39.984375 0 \nL 28.421875 21.6875 \nL 8.296875 0 \nL -2.59375 0 \nL 24.3125 28.8125 \nL 10.015625 54.6875 \nL 20.3125 54.6875 \nL 30.8125 34.90625 \nL 49.125 54.6875 \nz\n\" id=\"DejaVuSans-Oblique-120\"/>\n     </defs>\n     <g style=\"fill:#262626;\" transform=\"translate(164.204844 273.022188)scale(0.12 -0.12)\">\n      <use transform=\"translate(0 0.3125)\" xlink:href=\"#DejaVuSans-Oblique-120\"/>\n      <use transform=\"translate(59.179688 -16.09375)scale(0.7)\" xlink:href=\"#DejaVuSans-49\"/>\n     </g>\n    </g>\n   </g>\n   <g id=\"matplotlib.axis_2\">\n    <g id=\"ytick_1\">\n     <g id=\"line2d_4\">\n      <path clip-path=\"url(#p923ca5c768)\" d=\"M 59.024844 226.111531 \nL 282.224844 226.111531 \n\" style=\"fill:none;stroke:#ffffff;stroke-linecap:round;\"/>\n     </g>\n     <g id=\"text_5\">\n      <!-- −0.2 -->\n      <defs>\n       <path d=\"M 10.59375 35.5 \nL 73.1875 35.5 \nL 73.1875 27.203125 \nL 10.59375 27.203125 \nz\n\" id=\"DejaVuSans-8722\"/>\n       <path d=\"M 19.1875 8.296875 \nL 53.609375 8.296875 \nL 53.609375 0 \nL 7.328125 0 \nL 7.328125 8.296875 \nQ 12.9375 14.109375 22.625 23.890625 \nQ 32.328125 33.6875 34.8125 36.53125 \nQ 39.546875 41.84375 41.421875 45.53125 \nQ 43.3125 49.21875 43.3125 52.78125 \nQ 43.3125 58.59375 39.234375 62.25 \nQ 35.15625 65.921875 28.609375 65.921875 \nQ 23.96875 65.921875 18.8125 64.3125 \nQ 13.671875 62.703125 7.8125 59.421875 \nL 7.8125 69.390625 \nQ 13.765625 71.78125 18.9375 73 \nQ 24.125 74.21875 28.421875 74.21875 \nQ 39.75 74.21875 46.484375 68.546875 \nQ 53.21875 62.890625 53.21875 53.421875 \nQ 53.21875 48.921875 51.53125 44.890625 \nQ 49.859375 40.875 45.40625 35.40625 \nQ 44.1875 33.984375 37.640625 27.21875 \nQ 31.109375 20.453125 19.1875 8.296875 \nz\n\" id=\"DejaVuSans-50\"/>\n      </defs>\n      <g style=\"fill:#262626;\" transform=\"translate(22.81375 230.290671)scale(0.11 -0.11)\">\n       <use xlink:href=\"#DejaVuSans-8722\"/>\n       <use x=\"83.789062\" xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"147.412109\" xlink:href=\"#DejaVuSans-46\"/>\n       <use x=\"179.199219\" xlink:href=\"#DejaVuSans-50\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_2\">\n     <g id=\"line2d_5\">\n      <path clip-path=\"url(#p923ca5c768)\" d=\"M 59.024844 199.967512 \nL 282.224844 199.967512 \n\" style=\"fill:none;stroke:#ffffff;stroke-linecap:round;\"/>\n     </g>\n     <g id=\"text_6\">\n      <!-- 0.0 -->\n      <g style=\"fill:#262626;\" transform=\"translate(32.031406 204.146653)scale(0.11 -0.11)\">\n       <use xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\n       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_3\">\n     <g id=\"line2d_6\">\n      <path clip-path=\"url(#p923ca5c768)\" d=\"M 59.024844 173.823494 \nL 282.224844 173.823494 \n\" style=\"fill:none;stroke:#ffffff;stroke-linecap:round;\"/>\n     </g>\n     <g id=\"text_7\">\n      <!-- 0.2 -->\n      <g style=\"fill:#262626;\" transform=\"translate(32.031406 178.002635)scale(0.11 -0.11)\">\n       <use xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\n       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-50\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_4\">\n     <g id=\"line2d_7\">\n      <path clip-path=\"url(#p923ca5c768)\" d=\"M 59.024844 147.679476 \nL 282.224844 147.679476 \n\" style=\"fill:none;stroke:#ffffff;stroke-linecap:round;\"/>\n     </g>\n     <g id=\"text_8\">\n      <!-- 0.4 -->\n      <defs>\n       <path d=\"M 37.796875 64.3125 \nL 12.890625 25.390625 \nL 37.796875 25.390625 \nz\nM 35.203125 72.90625 \nL 47.609375 72.90625 \nL 47.609375 25.390625 \nL 58.015625 25.390625 \nL 58.015625 17.1875 \nL 47.609375 17.1875 \nL 47.609375 0 \nL 37.796875 0 \nL 37.796875 17.1875 \nL 4.890625 17.1875 \nL 4.890625 26.703125 \nz\n\" id=\"DejaVuSans-52\"/>\n      </defs>\n      <g style=\"fill:#262626;\" transform=\"translate(32.031406 151.858617)scale(0.11 -0.11)\">\n       <use xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\n       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-52\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_5\">\n     <g id=\"line2d_8\">\n      <path clip-path=\"url(#p923ca5c768)\" d=\"M 59.024844 121.535458 \nL 282.224844 121.535458 \n\" style=\"fill:none;stroke:#ffffff;stroke-linecap:round;\"/>\n     </g>\n     <g id=\"text_9\">\n      <!-- 0.6 -->\n      <defs>\n       <path d=\"M 33.015625 40.375 \nQ 26.375 40.375 22.484375 35.828125 \nQ 18.609375 31.296875 18.609375 23.390625 \nQ 18.609375 15.53125 22.484375 10.953125 \nQ 26.375 6.390625 33.015625 6.390625 \nQ 39.65625 6.390625 43.53125 10.953125 \nQ 47.40625 15.53125 47.40625 23.390625 \nQ 47.40625 31.296875 43.53125 35.828125 \nQ 39.65625 40.375 33.015625 40.375 \nz\nM 52.59375 71.296875 \nL 52.59375 62.3125 \nQ 48.875 64.0625 45.09375 64.984375 \nQ 41.3125 65.921875 37.59375 65.921875 \nQ 27.828125 65.921875 22.671875 59.328125 \nQ 17.53125 52.734375 16.796875 39.40625 \nQ 19.671875 43.65625 24.015625 45.921875 \nQ 28.375 48.1875 33.59375 48.1875 \nQ 44.578125 48.1875 50.953125 41.515625 \nQ 57.328125 34.859375 57.328125 23.390625 \nQ 57.328125 12.15625 50.6875 5.359375 \nQ 44.046875 -1.421875 33.015625 -1.421875 \nQ 20.359375 -1.421875 13.671875 8.265625 \nQ 6.984375 17.96875 6.984375 36.375 \nQ 6.984375 53.65625 15.1875 63.9375 \nQ 23.390625 74.21875 37.203125 74.21875 \nQ 40.921875 74.21875 44.703125 73.484375 \nQ 48.484375 72.75 52.59375 71.296875 \nz\n\" id=\"DejaVuSans-54\"/>\n      </defs>\n      <g style=\"fill:#262626;\" transform=\"translate(32.031406 125.714599)scale(0.11 -0.11)\">\n       <use xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\n       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-54\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_6\">\n     <g id=\"line2d_9\">\n      <path clip-path=\"url(#p923ca5c768)\" d=\"M 59.024844 95.39144 \nL 282.224844 95.39144 \n\" style=\"fill:none;stroke:#ffffff;stroke-linecap:round;\"/>\n     </g>\n     <g id=\"text_10\">\n      <!-- 0.8 -->\n      <defs>\n       <path d=\"M 31.78125 34.625 \nQ 24.75 34.625 20.71875 30.859375 \nQ 16.703125 27.09375 16.703125 20.515625 \nQ 16.703125 13.921875 20.71875 10.15625 \nQ 24.75 6.390625 31.78125 6.390625 \nQ 38.8125 6.390625 42.859375 10.171875 \nQ 46.921875 13.96875 46.921875 20.515625 \nQ 46.921875 27.09375 42.890625 30.859375 \nQ 38.875 34.625 31.78125 34.625 \nz\nM 21.921875 38.8125 \nQ 15.578125 40.375 12.03125 44.71875 \nQ 8.5 49.078125 8.5 55.328125 \nQ 8.5 64.0625 14.71875 69.140625 \nQ 20.953125 74.21875 31.78125 74.21875 \nQ 42.671875 74.21875 48.875 69.140625 \nQ 55.078125 64.0625 55.078125 55.328125 \nQ 55.078125 49.078125 51.53125 44.71875 \nQ 48 40.375 41.703125 38.8125 \nQ 48.828125 37.15625 52.796875 32.3125 \nQ 56.78125 27.484375 56.78125 20.515625 \nQ 56.78125 9.90625 50.3125 4.234375 \nQ 43.84375 -1.421875 31.78125 -1.421875 \nQ 19.734375 -1.421875 13.25 4.234375 \nQ 6.78125 9.90625 6.78125 20.515625 \nQ 6.78125 27.484375 10.78125 32.3125 \nQ 14.796875 37.15625 21.921875 38.8125 \nz\nM 18.3125 54.390625 \nQ 18.3125 48.734375 21.84375 45.5625 \nQ 25.390625 42.390625 31.78125 42.390625 \nQ 38.140625 42.390625 41.71875 45.5625 \nQ 45.3125 48.734375 45.3125 54.390625 \nQ 45.3125 60.0625 41.71875 63.234375 \nQ 38.140625 66.40625 31.78125 66.40625 \nQ 25.390625 66.40625 21.84375 63.234375 \nQ 18.3125 60.0625 18.3125 54.390625 \nz\n\" id=\"DejaVuSans-56\"/>\n      </defs>\n      <g style=\"fill:#262626;\" transform=\"translate(32.031406 99.570581)scale(0.11 -0.11)\">\n       <use xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\n       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-56\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_7\">\n     <g id=\"line2d_10\">\n      <path clip-path=\"url(#p923ca5c768)\" d=\"M 59.024844 69.247422 \nL 282.224844 69.247422 \n\" style=\"fill:none;stroke:#ffffff;stroke-linecap:round;\"/>\n     </g>\n     <g id=\"text_11\">\n      <!-- 1.0 -->\n      <g style=\"fill:#262626;\" transform=\"translate(32.031406 73.426563)scale(0.11 -0.11)\">\n       <use xlink:href=\"#DejaVuSans-49\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\n       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_8\">\n     <g id=\"line2d_11\">\n      <path clip-path=\"url(#p923ca5c768)\" d=\"M 59.024844 43.103404 \nL 282.224844 43.103404 \n\" style=\"fill:none;stroke:#ffffff;stroke-linecap:round;\"/>\n     </g>\n     <g id=\"text_12\">\n      <!-- 1.2 -->\n      <g style=\"fill:#262626;\" transform=\"translate(32.031406 47.282544)scale(0.11 -0.11)\">\n       <use xlink:href=\"#DejaVuSans-49\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\n       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-50\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"text_13\">\n     <!-- $x_2$ -->\n     <g style=\"fill:#262626;\" transform=\"translate(16.318125 137.458125)rotate(-90)scale(0.12 -0.12)\">\n      <use transform=\"translate(0 0.3125)\" xlink:href=\"#DejaVuSans-Oblique-120\"/>\n      <use transform=\"translate(59.179688 -16.09375)scale(0.7)\" xlink:href=\"#DejaVuSans-50\"/>\n     </g>\n    </g>\n   </g>\n   <g id=\"PathCollection_1\">\n    <defs>\n     <path d=\"M 0 3 \nC 0.795609 3 1.55874 2.683901 2.12132 2.12132 \nC 2.683901 1.55874 3 0.795609 3 0 \nC 3 -0.795609 2.683901 -1.55874 2.12132 -2.12132 \nC 1.55874 -2.683901 0.795609 -3 0 -3 \nC -0.795609 -3 -1.55874 -2.683901 -2.12132 -2.12132 \nC -2.683901 -1.55874 -3 -0.795609 -3 0 \nC -3 0.795609 -2.683901 1.55874 -2.12132 2.12132 \nC -1.55874 2.683901 -0.795609 3 0 3 \nz\n\" id=\"m15ef04e062\" style=\"stroke:#333333;\"/>\n    </defs>\n    <g clip-path=\"url(#p923ca5c768)\">\n     <use style=\"fill:#4c72b0;stroke:#333333;\" x=\"234.404252\" xlink:href=\"#m15ef04e062\" y=\"68.384105\"/>\n     <use style=\"fill:#4c72b0;stroke:#333333;\" x=\"259.41507\" xlink:href=\"#m15ef04e062\" y=\"86.321473\"/>\n     <use style=\"fill:#4c72b0;stroke:#333333;\" x=\"233.955552\" xlink:href=\"#m15ef04e062\" y=\"32.201761\"/>\n     <use style=\"fill:#4c72b0;stroke:#333333;\" x=\"242.530645\" xlink:href=\"#m15ef04e062\" y=\"76.410295\"/>\n     <use style=\"fill:#4c72b0;stroke:#333333;\" x=\"228.298619\" xlink:href=\"#m15ef04e062\" y=\"75.113513\"/>\n     <use style=\"fill:#4c72b0;stroke:#333333;\" x=\"243.096312\" xlink:href=\"#m15ef04e062\" y=\"64.240432\"/>\n     <use style=\"fill:#4c72b0;stroke:#333333;\" x=\"242.905832\" xlink:href=\"#m15ef04e062\" y=\"99.469304\"/>\n     <use style=\"fill:#4c72b0;stroke:#333333;\" x=\"239.091527\" xlink:href=\"#m15ef04e062\" y=\"60.757091\"/>\n     <use style=\"fill:#4c72b0;stroke:#333333;\" x=\"111.704097\" xlink:href=\"#m15ef04e062\" y=\"209.805343\"/>\n     <use style=\"fill:#4c72b0;stroke:#333333;\" x=\"234.889442\" xlink:href=\"#m15ef04e062\" y=\"86.009157\"/>\n     <use style=\"fill:#4c72b0;stroke:#333333;\" x=\"269.651916\" xlink:href=\"#m15ef04e062\" y=\"84.627665\"/>\n     <use style=\"fill:#4c72b0;stroke:#333333;\" x=\"209.347529\" xlink:href=\"#m15ef04e062\" y=\"59.971363\"/>\n     <use style=\"fill:#4c72b0;stroke:#333333;\" x=\"254.410449\" xlink:href=\"#m15ef04e062\" y=\"61.123869\"/>\n     <use style=\"fill:#4c72b0;stroke:#333333;\" x=\"246.326486\" xlink:href=\"#m15ef04e062\" y=\"78.727261\"/>\n     <use style=\"fill:#4c72b0;stroke:#333333;\" x=\"105.295624\" xlink:href=\"#m15ef04e062\" y=\"223.375257\"/>\n     <use style=\"fill:#4c72b0;stroke:#333333;\" x=\"244.742909\" xlink:href=\"#m15ef04e062\" y=\"94.283678\"/>\n     <use style=\"fill:#4c72b0;stroke:#333333;\" x=\"226.306989\" xlink:href=\"#m15ef04e062\" y=\"59.231074\"/>\n     <use style=\"fill:#4c72b0;stroke:#333333;\" x=\"119.02833\" xlink:href=\"#m15ef04e062\" y=\"195.348962\"/>\n     <use style=\"fill:#4c72b0;stroke:#333333;\" x=\"75.212836\" xlink:href=\"#m15ef04e062\" y=\"219.020445\"/>\n     <use style=\"fill:#4c72b0;stroke:#333333;\" x=\"97.517183\" xlink:href=\"#m15ef04e062\" y=\"196.810612\"/>\n     <use style=\"fill:#4c72b0;stroke:#333333;\" x=\"108.057991\" xlink:href=\"#m15ef04e062\" y=\"184.290456\"/>\n     <use style=\"fill:#4c72b0;stroke:#333333;\" x=\"235.416167\" xlink:href=\"#m15ef04e062\" y=\"69.839079\"/>\n     <use style=\"fill:#4c72b0;stroke:#333333;\" x=\"108.772629\" xlink:href=\"#m15ef04e062\" y=\"217.821456\"/>\n     <use style=\"fill:#4c72b0;stroke:#333333;\" x=\"125.233571\" xlink:href=\"#m15ef04e062\" y=\"208.108716\"/>\n     <use style=\"fill:#4c72b0;stroke:#333333;\" x=\"132.306674\" xlink:href=\"#m15ef04e062\" y=\"193.218954\"/>\n     <use style=\"fill:#4c72b0;stroke:#333333;\" x=\"93.766673\" xlink:href=\"#m15ef04e062\" y=\"185.341641\"/>\n     <use style=\"fill:#4c72b0;stroke:#333333;\" x=\"248.561806\" xlink:href=\"#m15ef04e062\" y=\"66.646346\"/>\n     <use style=\"fill:#4c72b0;stroke:#333333;\" x=\"104.451805\" xlink:href=\"#m15ef04e062\" y=\"202.240361\"/>\n     <use style=\"fill:#4c72b0;stroke:#333333;\" x=\"252.154985\" xlink:href=\"#m15ef04e062\" y=\"54.002354\"/>\n     <use style=\"fill:#4c72b0;stroke:#333333;\" x=\"110.665922\" xlink:href=\"#m15ef04e062\" y=\"193.005533\"/>\n     <use style=\"fill:#4c72b0;stroke:#333333;\" x=\"235.470843\" xlink:href=\"#m15ef04e062\" y=\"71.525344\"/>\n     <use style=\"fill:#4c72b0;stroke:#333333;\" x=\"95.525759\" xlink:href=\"#m15ef04e062\" y=\"197.410096\"/>\n     <use style=\"fill:#4c72b0;stroke:#333333;\" x=\"100.041614\" xlink:href=\"#m15ef04e062\" y=\"223.364828\"/>\n     <use style=\"fill:#4c72b0;stroke:#333333;\" x=\"139.512124\" xlink:href=\"#m15ef04e062\" y=\"187.194179\"/>\n     <use style=\"fill:#4c72b0;stroke:#333333;\" x=\"110.891577\" xlink:href=\"#m15ef04e062\" y=\"204.049823\"/>\n     <use style=\"fill:#4c72b0;stroke:#333333;\" x=\"97.743754\" xlink:href=\"#m15ef04e062\" y=\"188.21932\"/>\n     <use style=\"fill:#4c72b0;stroke:#333333;\" x=\"111.575062\" xlink:href=\"#m15ef04e062\" y=\"190.188013\"/>\n     <use style=\"fill:#4c72b0;stroke:#333333;\" x=\"241.325173\" xlink:href=\"#m15ef04e062\" y=\"81.124082\"/>\n     <use style=\"fill:#4c72b0;stroke:#333333;\" x=\"95.626088\" xlink:href=\"#m15ef04e062\" y=\"193.094261\"/>\n     <use style=\"fill:#4c72b0;stroke:#333333;\" x=\"251.842041\" xlink:href=\"#m15ef04e062\" y=\"75.752215\"/>\n     <use style=\"fill:#4c72b0;stroke:#333333;\" x=\"141.389301\" xlink:href=\"#m15ef04e062\" y=\"211.998872\"/>\n     <use style=\"fill:#4c72b0;stroke:#333333;\" x=\"119.30396\" xlink:href=\"#m15ef04e062\" y=\"205.722659\"/>\n     <use style=\"fill:#4c72b0;stroke:#333333;\" x=\"79.597615\" xlink:href=\"#m15ef04e062\" y=\"183.044715\"/>\n     <use style=\"fill:#4c72b0;stroke:#333333;\" x=\"109.394854\" xlink:href=\"#m15ef04e062\" y=\"194.332877\"/>\n     <use style=\"fill:#4c72b0;stroke:#333333;\" x=\"259.192382\" xlink:href=\"#m15ef04e062\" y=\"68.162187\"/>\n     <use style=\"fill:#4c72b0;stroke:#333333;\" x=\"235.802155\" xlink:href=\"#m15ef04e062\" y=\"85.325085\"/>\n     <use style=\"fill:#4c72b0;stroke:#333333;\" x=\"238.32645\" xlink:href=\"#m15ef04e062\" y=\"58.624972\"/>\n     <use style=\"fill:#4c72b0;stroke:#333333;\" x=\"263.435653\" xlink:href=\"#m15ef04e062\" y=\"68.673607\"/>\n     <use style=\"fill:#4c72b0;stroke:#333333;\" x=\"250.241063\" xlink:href=\"#m15ef04e062\" y=\"81.244437\"/>\n     <use style=\"fill:#4c72b0;stroke:#333333;\" x=\"114.935963\" xlink:href=\"#m15ef04e062\" y=\"198.332778\"/>\n     <use style=\"fill:#4c72b0;stroke:#333333;\" x=\"120.760877\" xlink:href=\"#m15ef04e062\" y=\"212.304082\"/>\n     <use style=\"fill:#4c72b0;stroke:#333333;\" x=\"108.356282\" xlink:href=\"#m15ef04e062\" y=\"211.351213\"/>\n     <use style=\"fill:#4c72b0;stroke:#333333;\" x=\"101.910067\" xlink:href=\"#m15ef04e062\" y=\"192.942896\"/>\n     <use style=\"fill:#4c72b0;stroke:#333333;\" x=\"234.317169\" xlink:href=\"#m15ef04e062\" y=\"72.253408\"/>\n     <use style=\"fill:#4c72b0;stroke:#333333;\" x=\"81.535948\" xlink:href=\"#m15ef04e062\" y=\"198.821316\"/>\n     <use style=\"fill:#4c72b0;stroke:#333333;\" x=\"106.466794\" xlink:href=\"#m15ef04e062\" y=\"180.107187\"/>\n     <use style=\"fill:#4c72b0;stroke:#333333;\" x=\"242.271086\" xlink:href=\"#m15ef04e062\" y=\"82.537137\"/>\n     <use style=\"fill:#4c72b0;stroke:#333333;\" x=\"221.303669\" xlink:href=\"#m15ef04e062\" y=\"69.50843\"/>\n     <use style=\"fill:#4c72b0;stroke:#333333;\" x=\"235.892862\" xlink:href=\"#m15ef04e062\" y=\"43.769059\"/>\n     <use style=\"fill:#4c72b0;stroke:#333333;\" x=\"234.038852\" xlink:href=\"#m15ef04e062\" y=\"62.403939\"/>\n     <use style=\"fill:#4c72b0;stroke:#333333;\" x=\"106.849981\" xlink:href=\"#m15ef04e062\" y=\"198.35885\"/>\n     <use style=\"fill:#4c72b0;stroke:#333333;\" x=\"122.0934\" xlink:href=\"#m15ef04e062\" y=\"197.201133\"/>\n     <use style=\"fill:#4c72b0;stroke:#333333;\" x=\"146.782597\" xlink:href=\"#m15ef04e062\" y=\"194.320336\"/>\n     <use style=\"fill:#4c72b0;stroke:#333333;\" x=\"239.38753\" xlink:href=\"#m15ef04e062\" y=\"70.509929\"/>\n     <use style=\"fill:#4c72b0;stroke:#333333;\" x=\"264.018538\" xlink:href=\"#m15ef04e062\" y=\"89.048031\"/>\n     <use style=\"fill:#4c72b0;stroke:#333333;\" x=\"104.866588\" xlink:href=\"#m15ef04e062\" y=\"181.16423\"/>\n     <use style=\"fill:#4c72b0;stroke:#333333;\" x=\"150.692161\" xlink:href=\"#m15ef04e062\" y=\"182.369203\"/>\n     <use style=\"fill:#4c72b0;stroke:#333333;\" x=\"254.886328\" xlink:href=\"#m15ef04e062\" y=\"89.190032\"/>\n     <use style=\"fill:#4c72b0;stroke:#333333;\" x=\"260.539867\" xlink:href=\"#m15ef04e062\" y=\"70.765873\"/>\n     <use style=\"fill:#4c72b0;stroke:#333333;\" x=\"261.738027\" xlink:href=\"#m15ef04e062\" y=\"75.534247\"/>\n     <use style=\"fill:#4c72b0;stroke:#333333;\" x=\"110.549755\" xlink:href=\"#m15ef04e062\" y=\"205.272921\"/>\n     <use style=\"fill:#4c72b0;stroke:#333333;\" x=\"115.493545\" xlink:href=\"#m15ef04e062\" y=\"186.904601\"/>\n     <use style=\"fill:#4c72b0;stroke:#333333;\" x=\"260.469281\" xlink:href=\"#m15ef04e062\" y=\"52.640707\"/>\n     <use style=\"fill:#4c72b0;stroke:#333333;\" x=\"271.339612\" xlink:href=\"#m15ef04e062\" y=\"58.851128\"/>\n     <use style=\"fill:#4c72b0;stroke:#333333;\" x=\"117.505214\" xlink:href=\"#m15ef04e062\" y=\"217.764794\"/>\n     <use style=\"fill:#4c72b0;stroke:#333333;\" x=\"269.531586\" xlink:href=\"#m15ef04e062\" y=\"46.129704\"/>\n     <use style=\"fill:#4c72b0;stroke:#333333;\" x=\"79.811595\" xlink:href=\"#m15ef04e062\" y=\"192.030853\"/>\n     <use style=\"fill:#4c72b0;stroke:#333333;\" x=\"232.198999\" xlink:href=\"#m15ef04e062\" y=\"90.939011\"/>\n     <use style=\"fill:#4c72b0;stroke:#333333;\" x=\"121.063453\" xlink:href=\"#m15ef04e062\" y=\"175.274196\"/>\n     <use style=\"fill:#4c72b0;stroke:#333333;\" x=\"224.449528\" xlink:href=\"#m15ef04e062\" y=\"77.183791\"/>\n     <use style=\"fill:#4c72b0;stroke:#333333;\" x=\"238.367636\" xlink:href=\"#m15ef04e062\" y=\"68.605572\"/>\n     <use style=\"fill:#4c72b0;stroke:#333333;\" x=\"253.737499\" xlink:href=\"#m15ef04e062\" y=\"79.272247\"/>\n     <use style=\"fill:#4c72b0;stroke:#333333;\" x=\"97.806607\" xlink:href=\"#m15ef04e062\" y=\"192.344642\"/>\n     <use style=\"fill:#4c72b0;stroke:#333333;\" x=\"128.343724\" xlink:href=\"#m15ef04e062\" y=\"198.309696\"/>\n     <use style=\"fill:#4c72b0;stroke:#333333;\" x=\"77.813065\" xlink:href=\"#m15ef04e062\" y=\"194.529868\"/>\n     <use style=\"fill:#4c72b0;stroke:#333333;\" x=\"248.129897\" xlink:href=\"#m15ef04e062\" y=\"59.571813\"/>\n     <use style=\"fill:#4c72b0;stroke:#333333;\" x=\"262.345625\" xlink:href=\"#m15ef04e062\" y=\"60.314034\"/>\n     <use style=\"fill:#4c72b0;stroke:#333333;\" x=\"241.116491\" xlink:href=\"#m15ef04e062\" y=\"66.638788\"/>\n     <use style=\"fill:#4c72b0;stroke:#333333;\" x=\"226.919551\" xlink:href=\"#m15ef04e062\" y=\"63.972653\"/>\n     <use style=\"fill:#4c72b0;stroke:#333333;\" x=\"230.1941\" xlink:href=\"#m15ef04e062\" y=\"78.292634\"/>\n     <use style=\"fill:#4c72b0;stroke:#333333;\" x=\"104.160215\" xlink:href=\"#m15ef04e062\" y=\"216.823009\"/>\n     <use style=\"fill:#4c72b0;stroke:#333333;\" x=\"124.76167\" xlink:href=\"#m15ef04e062\" y=\"229.874489\"/>\n     <use style=\"fill:#4c72b0;stroke:#333333;\" x=\"217.031155\" xlink:href=\"#m15ef04e062\" y=\"65.360947\"/>\n     <use style=\"fill:#4c72b0;stroke:#333333;\" x=\"249.282485\" xlink:href=\"#m15ef04e062\" y=\"69.203057\"/>\n     <use style=\"fill:#4c72b0;stroke:#333333;\" x=\"229.875906\" xlink:href=\"#m15ef04e062\" y=\"66.318666\"/>\n     <use style=\"fill:#4c72b0;stroke:#333333;\" x=\"106.186134\" xlink:href=\"#m15ef04e062\" y=\"211.903465\"/>\n     <use style=\"fill:#4c72b0;stroke:#333333;\" x=\"252.972993\" xlink:href=\"#m15ef04e062\" y=\"64.782193\"/>\n     <use style=\"fill:#4c72b0;stroke:#333333;\" x=\"264.639476\" xlink:href=\"#m15ef04e062\" y=\"73.807957\"/>\n     <use style=\"fill:#4c72b0;stroke:#333333;\" x=\"102.482497\" xlink:href=\"#m15ef04e062\" y=\"201.731318\"/>\n     <use style=\"fill:#4c72b0;stroke:#333333;\" x=\"249.922838\" xlink:href=\"#m15ef04e062\" y=\"62.866537\"/>\n     <use style=\"fill:#4c72b0;stroke:#333333;\" x=\"123.856301\" xlink:href=\"#m15ef04e062\" y=\"207.745412\"/>\n     <use style=\"fill:#4c72b0;stroke:#333333;\" x=\"231.711913\" xlink:href=\"#m15ef04e062\" y=\"49.899493\"/>\n     <use style=\"fill:#4c72b0;stroke:#333333;\" x=\"254.667367\" xlink:href=\"#m15ef04e062\" y=\"71.862476\"/>\n    </g>\n   </g>\n   <g id=\"PathCollection_2\">\n    <defs>\n     <path d=\"M 0 3 \nC 0.795609 3 1.55874 2.683901 2.12132 2.12132 \nC 2.683901 1.55874 3 0.795609 3 0 \nC 3 -0.795609 2.683901 -1.55874 2.12132 -2.12132 \nC 1.55874 -2.683901 0.795609 -3 0 -3 \nC -0.795609 -3 -1.55874 -2.683901 -2.12132 -2.12132 \nC -2.683901 -1.55874 -3 -0.795609 -3 0 \nC -3 0.795609 -2.683901 1.55874 -2.12132 2.12132 \nC -1.55874 2.683901 -0.795609 3 0 3 \nz\n\" id=\"m54ea328656\" style=\"stroke:#333333;\"/>\n    </defs>\n    <g clip-path=\"url(#p923ca5c768)\">\n     <use style=\"fill:#dd8452;stroke:#333333;\" x=\"110.430274\" xlink:href=\"#m54ea328656\" y=\"67.128969\"/>\n     <use style=\"fill:#dd8452;stroke:#333333;\" x=\"224.820154\" xlink:href=\"#m54ea328656\" y=\"198.722206\"/>\n     <use style=\"fill:#dd8452;stroke:#333333;\" x=\"247.569615\" xlink:href=\"#m54ea328656\" y=\"194.541869\"/>\n     <use style=\"fill:#dd8452;stroke:#333333;\" x=\"269.494659\" xlink:href=\"#m54ea328656\" y=\"173.187129\"/>\n     <use style=\"fill:#dd8452;stroke:#333333;\" x=\"229.024\" xlink:href=\"#m54ea328656\" y=\"226.737652\"/>\n     <use style=\"fill:#dd8452;stroke:#333333;\" x=\"254.828558\" xlink:href=\"#m54ea328656\" y=\"205.202456\"/>\n     <use style=\"fill:#dd8452;stroke:#333333;\" x=\"235.400431\" xlink:href=\"#m54ea328656\" y=\"206.60934\"/>\n     <use style=\"fill:#dd8452;stroke:#333333;\" x=\"102.210879\" xlink:href=\"#m54ea328656\" y=\"90.777555\"/>\n     <use style=\"fill:#dd8452;stroke:#333333;\" x=\"96.652661\" xlink:href=\"#m54ea328656\" y=\"81.941319\"/>\n     <use style=\"fill:#dd8452;stroke:#333333;\" x=\"116.071523\" xlink:href=\"#m54ea328656\" y=\"73.677504\"/>\n     <use style=\"fill:#dd8452;stroke:#333333;\" x=\"117.332774\" xlink:href=\"#m54ea328656\" y=\"92.070231\"/>\n     <use style=\"fill:#dd8452;stroke:#333333;\" x=\"246.06906\" xlink:href=\"#m54ea328656\" y=\"207.945808\"/>\n     <use style=\"fill:#dd8452;stroke:#333333;\" x=\"245.673555\" xlink:href=\"#m54ea328656\" y=\"180.226534\"/>\n     <use style=\"fill:#dd8452;stroke:#333333;\" x=\"97.762876\" xlink:href=\"#m54ea328656\" y=\"80.264357\"/>\n     <use style=\"fill:#dd8452;stroke:#333333;\" x=\"104.268306\" xlink:href=\"#m54ea328656\" y=\"66.863387\"/>\n     <use style=\"fill:#dd8452;stroke:#333333;\" x=\"101.895723\" xlink:href=\"#m54ea328656\" y=\"78.074315\"/>\n     <use style=\"fill:#dd8452;stroke:#333333;\" x=\"104.729364\" xlink:href=\"#m54ea328656\" y=\"56.040975\"/>\n     <use style=\"fill:#dd8452;stroke:#333333;\" x=\"118.571129\" xlink:href=\"#m54ea328656\" y=\"53.288603\"/>\n     <use style=\"fill:#dd8452;stroke:#333333;\" x=\"233.000622\" xlink:href=\"#m54ea328656\" y=\"202.161308\"/>\n     <use style=\"fill:#dd8452;stroke:#333333;\" x=\"267.096944\" xlink:href=\"#m54ea328656\" y=\"227.048275\"/>\n     <use style=\"fill:#dd8452;stroke:#333333;\" x=\"238.012436\" xlink:href=\"#m54ea328656\" y=\"212.738285\"/>\n     <use style=\"fill:#dd8452;stroke:#333333;\" x=\"243.054007\" xlink:href=\"#m54ea328656\" y=\"210.402422\"/>\n     <use style=\"fill:#dd8452;stroke:#333333;\" x=\"145.331111\" xlink:href=\"#m54ea328656\" y=\"64.423159\"/>\n     <use style=\"fill:#dd8452;stroke:#333333;\" x=\"107.299125\" xlink:href=\"#m54ea328656\" y=\"65.281255\"/>\n     <use style=\"fill:#dd8452;stroke:#333333;\" x=\"251.607695\" xlink:href=\"#m54ea328656\" y=\"197.020611\"/>\n     <use style=\"fill:#dd8452;stroke:#333333;\" x=\"106.960047\" xlink:href=\"#m54ea328656\" y=\"75.002382\"/>\n     <use style=\"fill:#dd8452;stroke:#333333;\" x=\"93.313315\" xlink:href=\"#m54ea328656\" y=\"59.588736\"/>\n     <use style=\"fill:#dd8452;stroke:#333333;\" x=\"240.119463\" xlink:href=\"#m54ea328656\" y=\"215.726292\"/>\n     <use style=\"fill:#dd8452;stroke:#333333;\" x=\"247.666295\" xlink:href=\"#m54ea328656\" y=\"189.443921\"/>\n     <use style=\"fill:#dd8452;stroke:#333333;\" x=\"227.534819\" xlink:href=\"#m54ea328656\" y=\"198.305888\"/>\n     <use style=\"fill:#dd8452;stroke:#333333;\" x=\"116.300123\" xlink:href=\"#m54ea328656\" y=\"60.91046\"/>\n     <use style=\"fill:#dd8452;stroke:#333333;\" x=\"112.566735\" xlink:href=\"#m54ea328656\" y=\"46.112625\"/>\n     <use style=\"fill:#dd8452;stroke:#333333;\" x=\"113.40348\" xlink:href=\"#m54ea328656\" y=\"86.141302\"/>\n     <use style=\"fill:#dd8452;stroke:#333333;\" x=\"132.381553\" xlink:href=\"#m54ea328656\" y=\"48.324779\"/>\n     <use style=\"fill:#dd8452;stroke:#333333;\" x=\"115.341911\" xlink:href=\"#m54ea328656\" y=\"59.263051\"/>\n     <use style=\"fill:#dd8452;stroke:#333333;\" x=\"250.399542\" xlink:href=\"#m54ea328656\" y=\"209.138007\"/>\n     <use style=\"fill:#dd8452;stroke:#333333;\" x=\"237.748768\" xlink:href=\"#m54ea328656\" y=\"198.118123\"/>\n     <use style=\"fill:#dd8452;stroke:#333333;\" x=\"111.386682\" xlink:href=\"#m54ea328656\" y=\"61.883263\"/>\n     <use style=\"fill:#dd8452;stroke:#333333;\" x=\"262.719844\" xlink:href=\"#m54ea328656\" y=\"196.934428\"/>\n     <use style=\"fill:#dd8452;stroke:#333333;\" x=\"109.92925\" xlink:href=\"#m54ea328656\" y=\"44.230192\"/>\n     <use style=\"fill:#dd8452;stroke:#333333;\" x=\"233.360279\" xlink:href=\"#m54ea328656\" y=\"215.530524\"/>\n     <use style=\"fill:#dd8452;stroke:#333333;\" x=\"113.771489\" xlink:href=\"#m54ea328656\" y=\"87.039696\"/>\n     <use style=\"fill:#dd8452;stroke:#333333;\" x=\"134.415949\" xlink:href=\"#m54ea328656\" y=\"70.21922\"/>\n     <use style=\"fill:#dd8452;stroke:#333333;\" x=\"258.055545\" xlink:href=\"#m54ea328656\" y=\"201.506357\"/>\n     <use style=\"fill:#dd8452;stroke:#333333;\" x=\"243.399405\" xlink:href=\"#m54ea328656\" y=\"206.7417\"/>\n     <use style=\"fill:#dd8452;stroke:#333333;\" x=\"121.611605\" xlink:href=\"#m54ea328656\" y=\"68.482419\"/>\n     <use style=\"fill:#dd8452;stroke:#333333;\" x=\"223.30093\" xlink:href=\"#m54ea328656\" y=\"198.154055\"/>\n     <use style=\"fill:#dd8452;stroke:#333333;\" x=\"227.803578\" xlink:href=\"#m54ea328656\" y=\"206.892294\"/>\n     <use style=\"fill:#dd8452;stroke:#333333;\" x=\"256.308873\" xlink:href=\"#m54ea328656\" y=\"196.314693\"/>\n     <use style=\"fill:#dd8452;stroke:#333333;\" x=\"87.679825\" xlink:href=\"#m54ea328656\" y=\"58.286742\"/>\n     <use style=\"fill:#dd8452;stroke:#333333;\" x=\"253.339979\" xlink:href=\"#m54ea328656\" y=\"196.397506\"/>\n     <use style=\"fill:#dd8452;stroke:#333333;\" x=\"234.096225\" xlink:href=\"#m54ea328656\" y=\"216.333033\"/>\n     <use style=\"fill:#dd8452;stroke:#333333;\" x=\"116.375843\" xlink:href=\"#m54ea328656\" y=\"49.339282\"/>\n     <use style=\"fill:#dd8452;stroke:#333333;\" x=\"97.262714\" xlink:href=\"#m54ea328656\" y=\"85.139545\"/>\n     <use style=\"fill:#dd8452;stroke:#333333;\" x=\"234.039764\" xlink:href=\"#m54ea328656\" y=\"204.537217\"/>\n     <use style=\"fill:#dd8452;stroke:#333333;\" x=\"111.817884\" xlink:href=\"#m54ea328656\" y=\"58.410268\"/>\n     <use style=\"fill:#dd8452;stroke:#333333;\" x=\"247.21773\" xlink:href=\"#m54ea328656\" y=\"197.530264\"/>\n     <use style=\"fill:#dd8452;stroke:#333333;\" x=\"115.16042\" xlink:href=\"#m54ea328656\" y=\"67.616188\"/>\n     <use style=\"fill:#dd8452;stroke:#333333;\" x=\"266.684164\" xlink:href=\"#m54ea328656\" y=\"216.516693\"/>\n     <use style=\"fill:#dd8452;stroke:#333333;\" x=\"115.618781\" xlink:href=\"#m54ea328656\" y=\"64.765363\"/>\n     <use style=\"fill:#dd8452;stroke:#333333;\" x=\"91.026126\" xlink:href=\"#m54ea328656\" y=\"88.772507\"/>\n     <use style=\"fill:#dd8452;stroke:#333333;\" x=\"240.555766\" xlink:href=\"#m54ea328656\" y=\"198.386125\"/>\n     <use style=\"fill:#dd8452;stroke:#333333;\" x=\"109.412735\" xlink:href=\"#m54ea328656\" y=\"56.362422\"/>\n     <use style=\"fill:#dd8452;stroke:#333333;\" x=\"260.511204\" xlink:href=\"#m54ea328656\" y=\"196.200788\"/>\n     <use style=\"fill:#dd8452;stroke:#333333;\" x=\"255.065205\" xlink:href=\"#m54ea328656\" y=\"210.551994\"/>\n     <use style=\"fill:#dd8452;stroke:#333333;\" x=\"224.475677\" xlink:href=\"#m54ea328656\" y=\"201.903543\"/>\n     <use style=\"fill:#dd8452;stroke:#333333;\" x=\"97.323439\" xlink:href=\"#m54ea328656\" y=\"85.41849\"/>\n     <use style=\"fill:#dd8452;stroke:#333333;\" x=\"114.516102\" xlink:href=\"#m54ea328656\" y=\"53.795722\"/>\n     <use style=\"fill:#dd8452;stroke:#333333;\" x=\"247.839684\" xlink:href=\"#m54ea328656\" y=\"205.058367\"/>\n     <use style=\"fill:#dd8452;stroke:#333333;\" x=\"148.421235\" xlink:href=\"#m54ea328656\" y=\"64.921723\"/>\n     <use style=\"fill:#dd8452;stroke:#333333;\" x=\"251.39822\" xlink:href=\"#m54ea328656\" y=\"199.056989\"/>\n     <use style=\"fill:#dd8452;stroke:#333333;\" x=\"89.105122\" xlink:href=\"#m54ea328656\" y=\"74.866054\"/>\n     <use style=\"fill:#dd8452;stroke:#333333;\" x=\"251.167965\" xlink:href=\"#m54ea328656\" y=\"191.040376\"/>\n     <use style=\"fill:#dd8452;stroke:#333333;\" x=\"69.170298\" xlink:href=\"#m54ea328656\" y=\"88.315854\"/>\n     <use style=\"fill:#dd8452;stroke:#333333;\" x=\"240.045442\" xlink:href=\"#m54ea328656\" y=\"209.36653\"/>\n     <use style=\"fill:#dd8452;stroke:#333333;\" x=\"99.513911\" xlink:href=\"#m54ea328656\" y=\"75.402625\"/>\n     <use style=\"fill:#dd8452;stroke:#333333;\" x=\"118.446081\" xlink:href=\"#m54ea328656\" y=\"72.94041\"/>\n     <use style=\"fill:#dd8452;stroke:#333333;\" x=\"244.569727\" xlink:href=\"#m54ea328656\" y=\"190.23094\"/>\n     <use style=\"fill:#dd8452;stroke:#333333;\" x=\"135.755895\" xlink:href=\"#m54ea328656\" y=\"86.926828\"/>\n     <use style=\"fill:#dd8452;stroke:#333333;\" x=\"244.095751\" xlink:href=\"#m54ea328656\" y=\"219.851606\"/>\n     <use style=\"fill:#dd8452;stroke:#333333;\" x=\"108.600978\" xlink:href=\"#m54ea328656\" y=\"56.353321\"/>\n     <use style=\"fill:#dd8452;stroke:#333333;\" x=\"250.53042\" xlink:href=\"#m54ea328656\" y=\"200.075074\"/>\n     <use style=\"fill:#dd8452;stroke:#333333;\" x=\"91.155616\" xlink:href=\"#m54ea328656\" y=\"77.158375\"/>\n     <use style=\"fill:#dd8452;stroke:#333333;\" x=\"262.873484\" xlink:href=\"#m54ea328656\" y=\"195.632136\"/>\n     <use style=\"fill:#dd8452;stroke:#333333;\" x=\"100.388099\" xlink:href=\"#m54ea328656\" y=\"57.912935\"/>\n     <use style=\"fill:#dd8452;stroke:#333333;\" x=\"269.038735\" xlink:href=\"#m54ea328656\" y=\"221.555766\"/>\n     <use style=\"fill:#dd8452;stroke:#333333;\" x=\"272.079389\" xlink:href=\"#m54ea328656\" y=\"208.600443\"/>\n     <use style=\"fill:#dd8452;stroke:#333333;\" x=\"245.012121\" xlink:href=\"#m54ea328656\" y=\"195.317897\"/>\n     <use style=\"fill:#dd8452;stroke:#333333;\" x=\"237.408423\" xlink:href=\"#m54ea328656\" y=\"216.074934\"/>\n     <use style=\"fill:#dd8452;stroke:#333333;\" x=\"244.204359\" xlink:href=\"#m54ea328656\" y=\"194.412203\"/>\n     <use style=\"fill:#dd8452;stroke:#333333;\" x=\"248.725963\" xlink:href=\"#m54ea328656\" y=\"218.678138\"/>\n     <use style=\"fill:#dd8452;stroke:#333333;\" x=\"256.740497\" xlink:href=\"#m54ea328656\" y=\"190.553229\"/>\n     <use style=\"fill:#dd8452;stroke:#333333;\" x=\"108.655814\" xlink:href=\"#m54ea328656\" y=\"71.397244\"/>\n     <use style=\"fill:#dd8452;stroke:#333333;\" x=\"212.086343\" xlink:href=\"#m54ea328656\" y=\"203.764845\"/>\n     <use style=\"fill:#dd8452;stroke:#333333;\" x=\"108.664758\" xlink:href=\"#m54ea328656\" y=\"71.29886\"/>\n     <use style=\"fill:#dd8452;stroke:#333333;\" x=\"125.587494\" xlink:href=\"#m54ea328656\" y=\"72.522239\"/>\n     <use style=\"fill:#dd8452;stroke:#333333;\" x=\"132.667815\" xlink:href=\"#m54ea328656\" y=\"44.557545\"/>\n    </g>\n   </g>\n   <g id=\"patch_3\">\n    <path d=\"M 59.024844 239.758125 \nL 59.024844 22.318125 \n\" style=\"fill:none;stroke:#ffffff;stroke-linecap:square;stroke-linejoin:miter;stroke-width:1.25;\"/>\n   </g>\n   <g id=\"patch_4\">\n    <path d=\"M 282.224844 239.758125 \nL 282.224844 22.318125 \n\" style=\"fill:none;stroke:#ffffff;stroke-linecap:square;stroke-linejoin:miter;stroke-width:1.25;\"/>\n   </g>\n   <g id=\"patch_5\">\n    <path d=\"M 59.024844 239.758125 \nL 282.224844 239.758125 \n\" style=\"fill:none;stroke:#ffffff;stroke-linecap:square;stroke-linejoin:miter;stroke-width:1.25;\"/>\n   </g>\n   <g id=\"patch_6\">\n    <path d=\"M 59.024844 22.318125 \nL 282.224844 22.318125 \n\" style=\"fill:none;stroke:#ffffff;stroke-linecap:square;stroke-linejoin:miter;stroke-width:1.25;\"/>\n   </g>\n   <g id=\"text_14\">\n    <!-- Dataset samples -->\n    <defs>\n     <path d=\"M 19.671875 64.796875 \nL 19.671875 8.109375 \nL 31.59375 8.109375 \nQ 46.6875 8.109375 53.6875 14.9375 \nQ 60.6875 21.78125 60.6875 36.53125 \nQ 60.6875 51.171875 53.6875 57.984375 \nQ 46.6875 64.796875 31.59375 64.796875 \nz\nM 9.8125 72.90625 \nL 30.078125 72.90625 \nQ 51.265625 72.90625 61.171875 64.09375 \nQ 71.09375 55.28125 71.09375 36.53125 \nQ 71.09375 17.671875 61.125 8.828125 \nQ 51.171875 0 30.078125 0 \nL 9.8125 0 \nz\n\" id=\"DejaVuSans-68\"/>\n     <path d=\"M 34.28125 27.484375 \nQ 23.390625 27.484375 19.1875 25 \nQ 14.984375 22.515625 14.984375 16.5 \nQ 14.984375 11.71875 18.140625 8.90625 \nQ 21.296875 6.109375 26.703125 6.109375 \nQ 34.1875 6.109375 38.703125 11.40625 \nQ 43.21875 16.703125 43.21875 25.484375 \nL 43.21875 27.484375 \nz\nM 52.203125 31.203125 \nL 52.203125 0 \nL 43.21875 0 \nL 43.21875 8.296875 \nQ 40.140625 3.328125 35.546875 0.953125 \nQ 30.953125 -1.421875 24.3125 -1.421875 \nQ 15.921875 -1.421875 10.953125 3.296875 \nQ 6 8.015625 6 15.921875 \nQ 6 25.140625 12.171875 29.828125 \nQ 18.359375 34.515625 30.609375 34.515625 \nL 43.21875 34.515625 \nL 43.21875 35.40625 \nQ 43.21875 41.609375 39.140625 45 \nQ 35.0625 48.390625 27.6875 48.390625 \nQ 23 48.390625 18.546875 47.265625 \nQ 14.109375 46.140625 10.015625 43.890625 \nL 10.015625 52.203125 \nQ 14.9375 54.109375 19.578125 55.046875 \nQ 24.21875 56 28.609375 56 \nQ 40.484375 56 46.34375 49.84375 \nQ 52.203125 43.703125 52.203125 31.203125 \nz\n\" id=\"DejaVuSans-97\"/>\n     <path d=\"M 18.3125 70.21875 \nL 18.3125 54.6875 \nL 36.8125 54.6875 \nL 36.8125 47.703125 \nL 18.3125 47.703125 \nL 18.3125 18.015625 \nQ 18.3125 11.328125 20.140625 9.421875 \nQ 21.96875 7.515625 27.59375 7.515625 \nL 36.8125 7.515625 \nL 36.8125 0 \nL 27.59375 0 \nQ 17.1875 0 13.234375 3.875 \nQ 9.28125 7.765625 9.28125 18.015625 \nL 9.28125 47.703125 \nL 2.6875 47.703125 \nL 2.6875 54.6875 \nL 9.28125 54.6875 \nL 9.28125 70.21875 \nz\n\" id=\"DejaVuSans-116\"/>\n     <path d=\"M 44.28125 53.078125 \nL 44.28125 44.578125 \nQ 40.484375 46.53125 36.375 47.5 \nQ 32.28125 48.484375 27.875 48.484375 \nQ 21.1875 48.484375 17.84375 46.4375 \nQ 14.5 44.390625 14.5 40.28125 \nQ 14.5 37.15625 16.890625 35.375 \nQ 19.28125 33.59375 26.515625 31.984375 \nL 29.59375 31.296875 \nQ 39.15625 29.25 43.1875 25.515625 \nQ 47.21875 21.78125 47.21875 15.09375 \nQ 47.21875 7.46875 41.1875 3.015625 \nQ 35.15625 -1.421875 24.609375 -1.421875 \nQ 20.21875 -1.421875 15.453125 -0.5625 \nQ 10.6875 0.296875 5.421875 2 \nL 5.421875 11.28125 \nQ 10.40625 8.6875 15.234375 7.390625 \nQ 20.0625 6.109375 24.8125 6.109375 \nQ 31.15625 6.109375 34.5625 8.28125 \nQ 37.984375 10.453125 37.984375 14.40625 \nQ 37.984375 18.0625 35.515625 20.015625 \nQ 33.0625 21.96875 24.703125 23.78125 \nL 21.578125 24.515625 \nQ 13.234375 26.265625 9.515625 29.90625 \nQ 5.8125 33.546875 5.8125 39.890625 \nQ 5.8125 47.609375 11.28125 51.796875 \nQ 16.75 56 26.8125 56 \nQ 31.78125 56 36.171875 55.265625 \nQ 40.578125 54.546875 44.28125 53.078125 \nz\n\" id=\"DejaVuSans-115\"/>\n     <path d=\"M 56.203125 29.59375 \nL 56.203125 25.203125 \nL 14.890625 25.203125 \nQ 15.484375 15.921875 20.484375 11.0625 \nQ 25.484375 6.203125 34.421875 6.203125 \nQ 39.59375 6.203125 44.453125 7.46875 \nQ 49.3125 8.734375 54.109375 11.28125 \nL 54.109375 2.78125 \nQ 49.265625 0.734375 44.1875 -0.34375 \nQ 39.109375 -1.421875 33.890625 -1.421875 \nQ 20.796875 -1.421875 13.15625 6.1875 \nQ 5.515625 13.8125 5.515625 26.8125 \nQ 5.515625 40.234375 12.765625 48.109375 \nQ 20.015625 56 32.328125 56 \nQ 43.359375 56 49.78125 48.890625 \nQ 56.203125 41.796875 56.203125 29.59375 \nz\nM 47.21875 32.234375 \nQ 47.125 39.59375 43.09375 43.984375 \nQ 39.0625 48.390625 32.421875 48.390625 \nQ 24.90625 48.390625 20.390625 44.140625 \nQ 15.875 39.890625 15.1875 32.171875 \nz\n\" id=\"DejaVuSans-101\"/>\n     <path id=\"DejaVuSans-32\"/>\n     <path d=\"M 52 44.1875 \nQ 55.375 50.25 60.0625 53.125 \nQ 64.75 56 71.09375 56 \nQ 79.640625 56 84.28125 50.015625 \nQ 88.921875 44.046875 88.921875 33.015625 \nL 88.921875 0 \nL 79.890625 0 \nL 79.890625 32.71875 \nQ 79.890625 40.578125 77.09375 44.375 \nQ 74.3125 48.1875 68.609375 48.1875 \nQ 61.625 48.1875 57.5625 43.546875 \nQ 53.515625 38.921875 53.515625 30.90625 \nL 53.515625 0 \nL 44.484375 0 \nL 44.484375 32.71875 \nQ 44.484375 40.625 41.703125 44.40625 \nQ 38.921875 48.1875 33.109375 48.1875 \nQ 26.21875 48.1875 22.15625 43.53125 \nQ 18.109375 38.875 18.109375 30.90625 \nL 18.109375 0 \nL 9.078125 0 \nL 9.078125 54.6875 \nL 18.109375 54.6875 \nL 18.109375 46.1875 \nQ 21.1875 51.21875 25.484375 53.609375 \nQ 29.78125 56 35.6875 56 \nQ 41.65625 56 45.828125 52.96875 \nQ 50 49.953125 52 44.1875 \nz\n\" id=\"DejaVuSans-109\"/>\n     <path d=\"M 18.109375 8.203125 \nL 18.109375 -20.796875 \nL 9.078125 -20.796875 \nL 9.078125 54.6875 \nL 18.109375 54.6875 \nL 18.109375 46.390625 \nQ 20.953125 51.265625 25.265625 53.625 \nQ 29.59375 56 35.59375 56 \nQ 45.5625 56 51.78125 48.09375 \nQ 58.015625 40.1875 58.015625 27.296875 \nQ 58.015625 14.40625 51.78125 6.484375 \nQ 45.5625 -1.421875 35.59375 -1.421875 \nQ 29.59375 -1.421875 25.265625 0.953125 \nQ 20.953125 3.328125 18.109375 8.203125 \nz\nM 48.6875 27.296875 \nQ 48.6875 37.203125 44.609375 42.84375 \nQ 40.53125 48.484375 33.40625 48.484375 \nQ 26.265625 48.484375 22.1875 42.84375 \nQ 18.109375 37.203125 18.109375 27.296875 \nQ 18.109375 17.390625 22.1875 11.75 \nQ 26.265625 6.109375 33.40625 6.109375 \nQ 40.53125 6.109375 44.609375 11.75 \nQ 48.6875 17.390625 48.6875 27.296875 \nz\n\" id=\"DejaVuSans-112\"/>\n     <path d=\"M 9.421875 75.984375 \nL 18.40625 75.984375 \nL 18.40625 0 \nL 9.421875 0 \nz\n\" id=\"DejaVuSans-108\"/>\n    </defs>\n    <g style=\"fill:#262626;\" transform=\"translate(120.282031 16.318125)scale(0.12 -0.12)\">\n     <use xlink:href=\"#DejaVuSans-68\"/>\n     <use x=\"77.001953\" xlink:href=\"#DejaVuSans-97\"/>\n     <use x=\"138.28125\" xlink:href=\"#DejaVuSans-116\"/>\n     <use x=\"177.490234\" xlink:href=\"#DejaVuSans-97\"/>\n     <use x=\"238.769531\" xlink:href=\"#DejaVuSans-115\"/>\n     <use x=\"290.869141\" xlink:href=\"#DejaVuSans-101\"/>\n     <use x=\"352.392578\" xlink:href=\"#DejaVuSans-116\"/>\n     <use x=\"391.601562\" xlink:href=\"#DejaVuSans-32\"/>\n     <use x=\"423.388672\" xlink:href=\"#DejaVuSans-115\"/>\n     <use x=\"475.488281\" xlink:href=\"#DejaVuSans-97\"/>\n     <use x=\"536.767578\" xlink:href=\"#DejaVuSans-109\"/>\n     <use x=\"634.179688\" xlink:href=\"#DejaVuSans-112\"/>\n     <use x=\"697.65625\" xlink:href=\"#DejaVuSans-108\"/>\n     <use x=\"725.439453\" xlink:href=\"#DejaVuSans-101\"/>\n     <use x=\"786.962891\" xlink:href=\"#DejaVuSans-115\"/>\n    </g>\n   </g>\n   <g id=\"legend_1\">\n    <g id=\"patch_7\">\n     <path d=\"M 199.891562 148.834063 \nL 274.524844 148.834063 \nQ 276.724844 148.834063 276.724844 146.634063 \nL 276.724844 115.442187 \nQ 276.724844 113.242188 274.524844 113.242188 \nL 199.891562 113.242188 \nQ 197.691562 113.242188 197.691562 115.442187 \nL 197.691562 146.634063 \nQ 197.691562 148.834063 199.891562 148.834063 \nz\n\" style=\"fill:#eaeaf2;opacity:0.8;stroke:#cccccc;stroke-linejoin:miter;\"/>\n    </g>\n    <g id=\"PathCollection_3\">\n     <g>\n      <use style=\"fill:#4c72b0;stroke:#333333;\" x=\"213.091562\" xlink:href=\"#m15ef04e062\" y=\"123.112969\"/>\n     </g>\n    </g>\n    <g id=\"text_15\">\n     <!-- Class 0 -->\n     <defs>\n      <path d=\"M 64.40625 67.28125 \nL 64.40625 56.890625 \nQ 59.421875 61.53125 53.78125 63.8125 \nQ 48.140625 66.109375 41.796875 66.109375 \nQ 29.296875 66.109375 22.65625 58.46875 \nQ 16.015625 50.828125 16.015625 36.375 \nQ 16.015625 21.96875 22.65625 14.328125 \nQ 29.296875 6.6875 41.796875 6.6875 \nQ 48.140625 6.6875 53.78125 8.984375 \nQ 59.421875 11.28125 64.40625 15.921875 \nL 64.40625 5.609375 \nQ 59.234375 2.09375 53.4375 0.328125 \nQ 47.65625 -1.421875 41.21875 -1.421875 \nQ 24.65625 -1.421875 15.125 8.703125 \nQ 5.609375 18.84375 5.609375 36.375 \nQ 5.609375 53.953125 15.125 64.078125 \nQ 24.65625 74.21875 41.21875 74.21875 \nQ 47.75 74.21875 53.53125 72.484375 \nQ 59.328125 70.75 64.40625 67.28125 \nz\n\" id=\"DejaVuSans-67\"/>\n     </defs>\n     <g style=\"fill:#262626;\" transform=\"translate(232.891562 126.000469)scale(0.11 -0.11)\">\n      <use xlink:href=\"#DejaVuSans-67\"/>\n      <use x=\"69.824219\" xlink:href=\"#DejaVuSans-108\"/>\n      <use x=\"97.607422\" xlink:href=\"#DejaVuSans-97\"/>\n      <use x=\"158.886719\" xlink:href=\"#DejaVuSans-115\"/>\n      <use x=\"210.986328\" xlink:href=\"#DejaVuSans-115\"/>\n      <use x=\"263.085938\" xlink:href=\"#DejaVuSans-32\"/>\n      <use x=\"294.873047\" xlink:href=\"#DejaVuSans-48\"/>\n     </g>\n    </g>\n    <g id=\"PathCollection_4\">\n     <g>\n      <use style=\"fill:#dd8452;stroke:#333333;\" x=\"213.091562\" xlink:href=\"#m54ea328656\" y=\"139.258906\"/>\n     </g>\n    </g>\n    <g id=\"text_16\">\n     <!-- Class 1 -->\n     <g style=\"fill:#262626;\" transform=\"translate(232.891562 142.146406)scale(0.11 -0.11)\">\n      <use xlink:href=\"#DejaVuSans-67\"/>\n      <use x=\"69.824219\" xlink:href=\"#DejaVuSans-108\"/>\n      <use x=\"97.607422\" xlink:href=\"#DejaVuSans-97\"/>\n      <use x=\"158.886719\" xlink:href=\"#DejaVuSans-115\"/>\n      <use x=\"210.986328\" xlink:href=\"#DejaVuSans-115\"/>\n      <use x=\"263.085938\" xlink:href=\"#DejaVuSans-32\"/>\n      <use x=\"294.873047\" xlink:href=\"#DejaVuSans-49\"/>\n     </g>\n    </g>\n   </g>\n  </g>\n </g>\n <defs>\n  <clipPath id=\"p923ca5c768\">\n   <rect height=\"217.44\" width=\"223.2\" x=\"59.024844\" y=\"22.318125\"/>\n  </clipPath>\n </defs>\n</svg>\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "visualize_samples(dataset.data, dataset.label)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mjajkKj1lF7N"
      },
      "source": [
        "**The data loader class**\n",
        "\n",
        "The class `torch.utils.data.DataLoader` represents a Python iterable over a dataset with support for automatic batching, multi-process data loading and many more features. The data loader communicates with the dataset using the function `__getitem__`, and stacks its outputs as tensors over the first dimension to form a batch.\n",
        "In contrast to the dataset class, we usually don't have to define our own data loader class, but can just create an object of it with the dataset as input. \n",
        "\n",
        "* `batch_size`: Number of samples to stack per batch\n",
        "* `shuffle`: If True, the data is returned in a random order. This is important during training for introducing stochasticity. \n",
        "* `num_workers`: Number of subprocesses to use for data loading. The default, 0, means that the data will be loaded in the main process which can slow down training for datasets where loading a data point takes a considerable amount of time (e.g. large images). More workers are recommended for those, but can cause issues on Windows computers. For tiny datasets as ours, 0 workers are usually faster.\n",
        "* `pin_memory`: If True, the data loader will copy Tensors into CUDA pinned memory before returning them. This can save some time for large data points on GPUs. Usually a good practice to use for a training set, but not necessarily for validation and test to save memory on the GPU.\n",
        "* `drop_last`: If True, the last batch is dropped in case it is smaller than the specified batch size. This occurs when the dataset size is not a multiple of the batch size. Only potentially helpful during training to keep a consistent batch size.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "id": "VBIlMqTWlF7N"
      },
      "outputs": [],
      "source": [
        "data_loader = data.DataLoader(dataset, batch_size=8, shuffle=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "id": "1xT_HYzolF7N",
        "outputId": "cf7d03f1-9b6f-41f7-ee8b-14d0a81e76f5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Data inputs torch.Size([8, 2]) \n",
            " tensor([[ 1.0483,  1.0488],\n",
            "        [ 1.1919, -0.1651],\n",
            "        [-0.0419,  0.1438],\n",
            "        [ 0.9428,  1.1949],\n",
            "        [-0.3102,  0.8541],\n",
            "        [-0.0642,  0.9325],\n",
            "        [ 0.9614,  1.0049],\n",
            "        [ 1.0212,  0.9275]])\n",
            "Data labels torch.Size([8]) \n",
            " tensor([0, 1, 0, 0, 1, 1, 0, 0])\n"
          ]
        }
      ],
      "source": [
        "# next(iter(...)) catches the first batch of the data loader\n",
        "# If shuffle is True, this will return a different batch every time we run this cell\n",
        "# For iterating over the whole dataset, we can simple use \"for batch in data_loader: ...\"\n",
        "data_inputs, data_labels = next(iter(data_loader))\n",
        "\n",
        "# The shape of the outputs are [batch_size, d_1,...,d_N] where d_1,...,d_N are the \n",
        "# dimensions of the data point returned from the dataset class\n",
        "print(\"Data inputs\", data_inputs.shape, \"\\n\", data_inputs)\n",
        "print(\"Data labels\", data_labels.shape, \"\\n\", data_labels)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s7uSknX8lF7N"
      },
      "source": [
        "**Optimization**\n",
        "\n",
        "After defining the model and the dataset, it is time to prepare the optimization of the model. During training, we will perform the following steps:\n",
        "\n",
        "1. Get a batch from the data loader\n",
        "2. Obtain the predictions from the model for the batch\n",
        "3. Calculate the loss based on the difference between predictions and labels\n",
        "4. Backpropagation: calculate the gradients for every parameter with respect to the loss\n",
        "5. Update the parameters of the model in the direction of the gradients"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ClFaQs3ClF7N"
      },
      "source": [
        "**Loss modules**\n",
        "\n",
        "We can calculate the loss for a batch by simply performing a few tensor operations as those are automatically added to the computation graph. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "id": "75BXWsY5lF7N"
      },
      "outputs": [],
      "source": [
        "loss_module = nn.BCEWithLogitsLoss()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_k5ly_gslF7N"
      },
      "source": [
        "**Stochastic Gradient Descent**\n",
        "\n",
        "For updating the parameters, PyTorch provides the package `torch.optim` that has most popular optimizers implemented.\n",
        "\n",
        "`torch.optim.SGD`. Stochastic Gradient Descent updates parameters by multiplying the gradients with a small constant, called learning rate, and subtracting those from the parameters (hence minimizing the loss). Therefore, we slowly move towards the direction of minimizing the loss. A good default value of the learning rate for a small network as ours is 0.1. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "id": "pTQmuGR6lF7N"
      },
      "outputs": [],
      "source": [
        "# Input to the optimizer are the parameters of the model: model.parameters()\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=0.1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dEkNtAtPlF7O"
      },
      "source": [
        "The optimizer provides two useful functions: `optimizer.step()`, and `optimizer.zero_grad()`. The step function updates the parameters based on the gradients as explained above. The function `optimizer.zero_grad()` sets the gradients of all parameters to zero. While this function seems less relevant at first, it is a crucial pre-step before performing backpropagation. If we would call the `backward` function on the loss while the parameter gradients are non-zero from the previous batch, the new gradients would actually be added to the previous ones instead of overwriting them. This is done because a parameter might occur multiple times in a computation graph, and we need to sum the gradients in this case instead of replacing them. Hence, remember to call `optimizer.zero_grad()` before calculating the gradients of a batch."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dtF03D72lF7O"
      },
      "source": [
        "**Training**\n",
        "\n",
        "As a first step, we create a slightly larger dataset and specify a data loader with a larger batch size. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "id": "_UaUGQn2lF7O"
      },
      "outputs": [],
      "source": [
        "train_dataset = XORDataset(size=2500)\n",
        "train_data_loader = data.DataLoader(train_dataset, batch_size=128, shuffle=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "id": "KcS89caClF7P"
      },
      "outputs": [],
      "source": [
        "def train_model(model, optimizer, data_loader, loss_module, num_epochs=100):\n",
        "    # Set model to train mode\n",
        "    model.train() \n",
        "    \n",
        "    # Training loop\n",
        "    for epoch in tqdm(range(num_epochs)):\n",
        "        for data_inputs, data_labels in data_loader:\n",
        "            \n",
        "            ## Step 1: Move input data to device (only strictly necessary if we use GPU)\n",
        "            #data_inputs = data_inputs.to(device)\n",
        "            #data_labels = data_labels.to(device)\n",
        "            \n",
        "            ## Step 2: Run the model on the input data\n",
        "            preds = model(data_inputs)\n",
        "            preds = preds.squeeze(dim=1) # Output is [Batch size, 1], but we want [Batch size]\n",
        "            \n",
        "            ## Step 3: Calculate the loss\n",
        "            loss = loss_module(preds, data_labels.float())\n",
        "            \n",
        "            ## Step 4: Perform backpropagation\n",
        "            # Before calculating the gradients, we need to ensure that they are all zero. \n",
        "            # The gradients would not be overwritten, but actually added to the existing ones.\n",
        "            optimizer.zero_grad() \n",
        "            # Perform backpropagation\n",
        "            loss.backward()\n",
        "            \n",
        "            ## Step 5: Update the parameters\n",
        "            optimizer.step()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "id": "JTudDRZAlF7P",
        "outputId": "a22f16c5-aa49-4fd6-81eb-404985b4da1a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49,
          "referenced_widgets": [
            "7297a27664f840f0a9c15b9d6e56379d",
            "f7e38c29c5704f37bc028b8c05e0d435",
            "ca6d652d6f27404ca411eea89649c358",
            "e5ab5ce429854932890da1f51affaa25",
            "c430963212284a3cb194a1cf82db5178",
            "bce2c1a6c267439bb12987515958be58",
            "3d0a98124b0d4fd3813a64742b498b42",
            "f2db9718c27946ca9e3aa9b3cceb22ca",
            "ac014a85bfd14070a6588b76bafc0faa",
            "f1fa2da315f94d3889d5e9d20511c46a",
            "79b1e9f8d2274e5aba7152b036b41eff"
          ]
        }
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "7297a27664f840f0a9c15b9d6e56379d",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "  0%|          | 0/100 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "train_model(model, optimizer, train_data_loader, loss_module)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fn82FS6OlF7P"
      },
      "source": [
        "**Saving a model**\n",
        "\n",
        "After finish training a model, we save the model to disk so that we can load the same weights at a later time. For this, we extract the so-called `state_dict` from the model which contains all learnable parameters. For our simple model, the state dict contains the following entries:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {
        "id": "xJk33IbtlF7P",
        "outputId": "68762f36-737b-40d8-821e-ec31a5b8f3f4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "OrderedDict([('linear1.weight', tensor([[ 2.8957, -2.1860],\n",
            "        [-2.4901, -2.5125],\n",
            "        [-2.3119,  2.9668],\n",
            "        [ 1.2837,  1.2051]])), ('linear1.bias', tensor([ 0.9271,  0.8499,  1.0310, -1.9309])), ('linear2.weight', tensor([[-3.7568, -3.5683, -3.7784, -2.3891]])), ('linear2.bias', tensor([0.3319]))])\n"
          ]
        }
      ],
      "source": [
        "state_dict = model.state_dict()\n",
        "print(state_dict)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BAl3fdEKlF7Q"
      },
      "source": [
        "To save the state dictionary, we can use `torch.save`:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {
        "id": "A9hqSo1NlF7Q"
      },
      "outputs": [],
      "source": [
        "# torch.save(object, filename). For the filename, any extension can be used\n",
        "torch.save(state_dict, \"our_model.tar\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oALP4aqwlF7T"
      },
      "source": [
        "To load a model from a state dict, we use the function `torch.load` to load the state dict from the disk, and the module function `load_state_dict` to overwrite our parameters with the new values:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {
        "id": "wt0px3V_lF7T",
        "outputId": "bd0d37e5-6b75-4a88-ce52-6dac6045b5b4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original model\n",
            " OrderedDict([('linear1.weight', tensor([[ 2.8957, -2.1860],\n",
            "        [-2.4901, -2.5125],\n",
            "        [-2.3119,  2.9668],\n",
            "        [ 1.2837,  1.2051]])), ('linear1.bias', tensor([ 0.9271,  0.8499,  1.0310, -1.9309])), ('linear2.weight', tensor([[-3.7568, -3.5683, -3.7784, -2.3891]])), ('linear2.bias', tensor([0.3319]))])\n",
            "\n",
            "Loaded model\n",
            " OrderedDict([('linear1.weight', tensor([[ 2.8957, -2.1860],\n",
            "        [-2.4901, -2.5125],\n",
            "        [-2.3119,  2.9668],\n",
            "        [ 1.2837,  1.2051]])), ('linear1.bias', tensor([ 0.9271,  0.8499,  1.0310, -1.9309])), ('linear2.weight', tensor([[-3.7568, -3.5683, -3.7784, -2.3891]])), ('linear2.bias', tensor([0.3319]))])\n"
          ]
        }
      ],
      "source": [
        "# Load state dict from the disk (make sure it is the same name as above)\n",
        "state_dict = torch.load(\"our_model.tar\")\n",
        "\n",
        "# Create a new model and load the state\n",
        "new_model = SimpleClassifier(num_inputs=2, num_hidden=4, num_outputs=1)\n",
        "new_model.load_state_dict(state_dict)\n",
        "\n",
        "# Verify that the parameters are the same\n",
        "print(\"Original model\\n\", model.state_dict())\n",
        "print(\"\\nLoaded model\\n\", new_model.state_dict())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KopRHs1olF7T"
      },
      "source": [
        "**Evaluation**\n",
        "\n",
        "Once we have trained a model, it is time to evaluate it on a held-out test set. As our dataset consist of randomly generated data points, we need to first create a test set with a corresponding data loader."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {
        "id": "bioPDrPIlF7T"
      },
      "outputs": [],
      "source": [
        "test_dataset = XORDataset(size=500)\n",
        "# drop_last -> Don't drop the last batch although it is smaller than 128\n",
        "test_data_loader = data.DataLoader(test_dataset, batch_size=128, shuffle=False, drop_last=False) "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {
        "id": "W6d3uzGnlF7U"
      },
      "outputs": [],
      "source": [
        "def eval_model(model, data_loader):\n",
        "    model.eval() # Set model to eval mode\n",
        "    true_preds, num_preds = 0., 0.\n",
        "    \n",
        "    with torch.no_grad(): # Deactivate gradients for the following code\n",
        "        for data_inputs, data_labels in data_loader:\n",
        "            \n",
        "            # Determine prediction of model on dev set\n",
        "            #data_inputs, data_labels = data_inputs.to(device), data_labels.to(device)\n",
        "            preds = model(data_inputs)\n",
        "            preds = preds.squeeze(dim=1)\n",
        "            preds = torch.sigmoid(preds) # Sigmoid to map predictions between 0 and 1\n",
        "            pred_labels = (preds >= 0.5).long() # Binarize predictions to 0 and 1\n",
        "            \n",
        "            # Keep records of predictions for the accuracy metric (true_preds=TP+TN, num_preds=TP+TN+FP+FN)\n",
        "            true_preds += (pred_labels == data_labels).sum()\n",
        "            num_preds += data_labels.shape[0]\n",
        "            \n",
        "    acc = true_preds / num_preds\n",
        "    print(f\"Accuracy of the model: {100.0*acc:4.2f}%\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "metadata": {
        "id": "rVkGgIRglF7U",
        "outputId": "50b5d3dc-2217-4f96-9081-b91b6eeb7dd7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy of the model: 100.00%\n"
          ]
        }
      ],
      "source": [
        "eval_model(model, test_data_loader)"
      ]
    }
  ]
}